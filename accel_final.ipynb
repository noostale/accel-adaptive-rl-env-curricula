{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    }
   ],
   "source": [
    "print(\"Start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import wandb\n",
    "import imageio\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from gymnasium.spaces import Box\n",
    "\n",
    "from minigrid.core.mission import MissionSpace\n",
    "from minigrid.core.world_object import Goal, Wall\n",
    "from minigrid.minigrid_env import MiniGridEnv, Grid\n",
    "from minigrid.wrappers import ImgObsWrapper\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ====================================================\n",
    "# 1. Custom MiniGrid Environment that returns only the image\n",
    "#    for SB3's PPO (which expects a Box space).\n",
    "# ====================================================\n",
    "class MyCustomGrid(MiniGridEnv):\n",
    "    \"\"\"\n",
    "    Simple MiniGrid environment that places random wall tiles\n",
    "    according to a config dict, returning only the 'image' observation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config=None, solvable_only=False, **kwargs):\n",
    "        if config is None:\n",
    "            config = {}\n",
    "        self.config = config\n",
    "        self.solvable_only = solvable_only\n",
    "\n",
    "        # Create a random number generator with the custom seed\n",
    "        self.rng = np.random.default_rng(seed=self.config.get(\"seed_val\"))\n",
    "\n",
    "        mission_space = MissionSpace(mission_func=lambda: \"get to the green goal square\")\n",
    "\n",
    "        super().__init__(\n",
    "            grid_size=self.config['width'],\n",
    "            max_steps=self.config['width'] * self.config['height'] * 2, # max_steps is typically 2x the grid size\n",
    "            see_through_walls=False,\n",
    "            agent_view_size=5,                      # Size of the agent's view square\n",
    "            mission_space=mission_space,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # Manually define our observation_space as a single Box (the image).\n",
    "        # By default, MiniGrid's image shape is (view_size, view_size, 3) if using partial obs,\n",
    "        # or (height, width, 3) if using full-grid observation. We'll do full-grid here:\n",
    "        # We'll define (self.height, self.width, 3) as the shape.\n",
    "        # In practice, \"image\" shape can vary if partial observations are used.\n",
    "        self.observation_space = Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(self.agent_view_size, self.agent_view_size, 3),\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "\n",
    "            \n",
    "    def _gen_grid(self, width, height):\n",
    "        \"\"\"\n",
    "        Generate a new environment layout ensuring solvability if required.\n",
    "        \"\"\"\n",
    "        \n",
    "        check_stuck = 0\n",
    "        while True:  # Keep regenerating until a solvable layout is found\n",
    "            self.grid = Grid(width, height)\n",
    "            self.grid.wall_rect(0, 0, width, height)\n",
    "\n",
    "            # Place the goal\n",
    "            goal_pos = self.config.get(\"goal_pos\")\n",
    "            if goal_pos is None:\n",
    "                while True:\n",
    "                    goal_r = self.rng.integers(1, height - 1)\n",
    "                    goal_c = self.rng.integers(1, width - 1)\n",
    "                    if self.grid.get(goal_c, goal_r) is None:\n",
    "                        self.put_obj(Goal(), goal_c, goal_r)\n",
    "                        self.config[\"goal_pos\"] = (goal_c, goal_r)\n",
    "                        break\n",
    "            else:\n",
    "                self.put_obj(Goal(), goal_pos[0], goal_pos[1])\n",
    "\n",
    "            # Place the agent\n",
    "            start_pos = self.config.get(\"start_pos\")\n",
    "            if start_pos is None:\n",
    "                while True:\n",
    "                    start_r = self.rng.integers(1, height - 1)\n",
    "                    start_c = self.rng.integers(1, width - 1)\n",
    "                    if self.grid.get(start_c, start_r) is None and (start_c, start_r) != self.config[\"goal_pos\"]:\n",
    "                        self.agent_pos = (start_c, start_r)\n",
    "                        self.agent_dir = self.rng.integers(0, 4)\n",
    "                        self.config[\"start_pos\"] = (start_c, start_r)\n",
    "                        break\n",
    "            else:\n",
    "                self.agent_pos = start_pos\n",
    "                self.agent_dir = self.rng.integers(0, 4)\n",
    "                self.config[\"start_pos\"] = start_pos\n",
    "            \n",
    "            placed_blocks = 0\n",
    "            \n",
    "            # Maximum number of tries to place the blocks\n",
    "            max_num_tries = 100\n",
    "            \n",
    "            # Place random walls using config parameters\n",
    "            while placed_blocks < self.config[\"num_blocks\"]:\n",
    "                max_num_tries -= 1\n",
    "                r = self.rng.integers(1, height - 1)\n",
    "                c = self.rng.integers(1, width - 1)\n",
    "                if max_num_tries <= 0:\n",
    "                    print(\"Could not place all blocks in the grid.\")\n",
    "                    break\n",
    "                if self.grid.get(c, r) is None and (c, r) != self.config[\"start_pos\"] and (c, r) != self.config[\"goal_pos\"]:\n",
    "                    self.put_obj(Wall(), c, r)\n",
    "                    placed_blocks += 1\n",
    "\n",
    "            # Check solvability if required\n",
    "            if not self.solvable_only or self._is_solvable():\n",
    "                break\n",
    "            \n",
    "            check_stuck += 1\n",
    "            if check_stuck > 50:\n",
    "                print(\"Re-randomizing start and goal positions...\")\n",
    "                self.config.pop(\"start_pos\", None)\n",
    "                self.config.pop(\"goal_pos\", None)\n",
    "                self.rng = np.random.default_rng(seed=self.config.get(\"seed_val\") + check_stuck)\n",
    "\n",
    "        \n",
    "    def _is_solvable(self):\n",
    "        \"\"\"\n",
    "        Uses Breadth-First Search (BFS) to check if there's a path \n",
    "        from the agent's start position to the goal.\n",
    "        \"\"\"\n",
    "        start_pos = self.config[\"start_pos\"]\n",
    "        goal_pos = self.config[\"goal_pos\"]\n",
    "        if not start_pos or not goal_pos:\n",
    "            return False\n",
    "\n",
    "        queue = deque([start_pos])\n",
    "        visited = set()\n",
    "        visited.add(start_pos)\n",
    "\n",
    "        while queue:\n",
    "            x, y = queue.popleft()\n",
    "            if (x, y) == goal_pos:\n",
    "                return True\n",
    "\n",
    "            # Possible moves: up, down, left, right\n",
    "            for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                nx, ny = x + dx, y + dy\n",
    "                cell_obj = self.grid.get(nx, ny)\n",
    "                if (\n",
    "                    1 <= nx < self.width - 1 and  # Stay within grid bounds\n",
    "                    1 <= ny < self.height - 1 and\n",
    "                    (nx, ny) not in visited and\n",
    "                    self.grid.get(nx, ny) is None or isinstance(cell_obj, Goal)\n",
    "                ):\n",
    "                    queue.append((nx, ny))\n",
    "                    visited.add((nx, ny))\n",
    "        return False  # No path found\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Override reset to ensure we only return the 'image' array\n",
    "        instead of a dict with 'image' and 'mission'.\n",
    "        \"\"\"\n",
    "        obs, info = super().reset(**kwargs)\n",
    "        obs = self._convert_obs(obs)\n",
    "        \n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Same for step: override to convert the dict observation into an image only.\n",
    "        \"\"\"\n",
    "        obs, reward, done, truncated, info = super().step(action)\n",
    "        obs = self._convert_obs(obs)\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "    def _convert_obs(self, original_obs):\n",
    "        \"\"\"\n",
    "        original_obs is typically {'image':..., 'mission':...}.\n",
    "        We'll just return original_obs['image'] to get a Box(low=0,high=255) shape.\n",
    "        \"\"\"\n",
    "        return original_obs[\"image\"]\n",
    "        #return np.transpose(original_obs[\"image\"], (2, 0, 1))\n",
    "    \n",
    "    def update_config(self, new_config):\n",
    "        self.config = new_config\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "\n",
    "def random_config(grid_size, num_blocks=None, seed=None):\n",
    "    max_blocks = int(((grid_size - 1) * (grid_size - 1)) / 2)\n",
    "    \n",
    "    if num_blocks is None:\n",
    "        num_blocks = np.random.randint(1, max_blocks)\n",
    "    else:\n",
    "        num_blocks = min(num_blocks, max_blocks)\n",
    "        \n",
    "    config = {\n",
    "        \"width\": grid_size,\n",
    "        \"height\": grid_size,\n",
    "        \"num_blocks\": num_blocks,\n",
    "        \"start_pos\": None,\n",
    "        \"goal_pos\": None,\n",
    "        \"edited\": False,\n",
    "        \"seed_val\": seed if seed is not None else np.random.randint(0, 1000)\n",
    "    }\n",
    "    \n",
    "    # Set the start and goal positions\n",
    "    env = MyCustomGrid(config)\n",
    "    \n",
    "    # Reset the environment to get the start and goal positions\n",
    "    env.reset()\n",
    "    \n",
    "    # Get the new config from the environment\n",
    "    config = env.config\n",
    "        \n",
    "    return config\n",
    "\n",
    "def print_level_from_config(config, solvable_only=False):\n",
    "    #print(\"Putting up the level from config:\", config)\n",
    "    env = MyCustomGrid(config, render_mode='rgb_array', solvable_only=solvable_only)\n",
    "    env.reset()\n",
    "    full_level_image = env.render()  # This should return an RGB image of the full grid\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(full_level_image)\n",
    "    plt.title(\"Level Configuration: \" + str(config))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "# Modify an existing configuration, adding randomness.\n",
    "def edit_config(old_config):\n",
    "    max_blocks = int(((old_config[\"width\"] - 1) * (old_config[\"height\"] - 1)) / 2)\n",
    "    \n",
    "    new_config = dict(old_config)\n",
    "    \n",
    "    # Randomly change the number of blocks\n",
    "    new_number_blocks = old_config[\"num_blocks\"] + np.random.choice([1, 2, 3])\n",
    "    \n",
    "    # Ensure the number of blocks is within bounds\n",
    "    new_config[\"num_blocks\"] = max(1, min(new_number_blocks, max_blocks))    \n",
    "    \n",
    "    # Mark the config as edited\n",
    "    new_config[\"edited\"] = True\n",
    "    \n",
    "    return new_config\n",
    "    \n",
    "\"\"\"\n",
    "def edit_config(old_config, difficulty_level=1):\n",
    "\n",
    "    width, height = old_config[\"width\"], old_config[\"height\"]\n",
    "    total_cells = width * height\n",
    "\n",
    "    # Define a baseline max number of blocks\n",
    "    max_blocks = int(0.6 * total_cells)  # Ensure we don't overcrowd (max 60% coverage)\n",
    "    \n",
    "    # Calculate the new number of blocks using a logarithmic scale\n",
    "    base_growth = int(np.log2(total_cells) * difficulty_level)\n",
    "    \n",
    "    # Introduce some randomness while keeping it within a reasonable range\n",
    "    growth_factor = np.random.randint(base_growth // 2, base_growth + 1)\n",
    "    \n",
    "    # Compute the new block count\n",
    "    new_number_blocks = old_config[\"num_blocks\"] + growth_factor\n",
    "    \n",
    "    # Ensure it's within the allowed range\n",
    "    new_config = dict(old_config)\n",
    "    new_config[\"num_blocks\"] = max(1, min(new_number_blocks, max_blocks))  \n",
    "    \n",
    "    # Mark as edited\n",
    "    new_config[\"edited\"] = True\n",
    "\n",
    "    return new_config\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 2. Simple “level buffer” \n",
    "# ====================================================\n",
    "# class to memorize generated levels and score\n",
    "class LevelBuffer: \n",
    "    def __init__(self, max_size=50):\n",
    "        self.max_size = max_size\n",
    "        self.data = []  # will store (config_dict, score)\n",
    "\n",
    "    def add(self, config, score):\n",
    "        self.data.append((config, score))\n",
    "        if len(self.data) > self.max_size:\n",
    "            self.data.sort(key=lambda x: x[1], reverse=True)\n",
    "            self.data = self.data[: self.max_size]\n",
    "            #it memorize only the highest score for each level\n",
    "\n",
    "    def sample_config(self): \n",
    "        # Samples a level from the buffer, weighting the probabilities \n",
    "        # based on the scores.\n",
    "        if len(self.data) == 0:\n",
    "            return None\n",
    "        scores = [item[1] for item in self.data]\n",
    "        total = sum(scores)\n",
    "        if total <= 1e-9:\n",
    "            # fallback to uniform\n",
    "            idx = np.random.randint(len(self.data))\n",
    "            return self.data[idx][0]\n",
    "        probs = [s / total for s in scores]\n",
    "        idx = np.random.choice(len(self.data), p=probs)\n",
    "        return self.data[idx][0]\n",
    "\n",
    "# ====================================================\n",
    "# 3. Utility Functions\n",
    "# ====================================================\n",
    "\n",
    "# Calculate regret using Generalized Advantage Estimation (GAE) with Stable-Baselines3's PPO model.\n",
    "# PLR approximates regret using a score function such as the positive value loss.\n",
    "def calculate_regret_gae(env, model, max_steps, gamma, lam):\n",
    "    \"\"\"\n",
    "    Calculate regret using Generalized Advantage Estimation (GAE)\n",
    "    with Stable-Baselines3's PPO model.\n",
    "    \"\"\"\n",
    "    obs, _ = env.reset()\n",
    "    regrets = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    values = []\n",
    "\n",
    "    for t in range(max_steps):\n",
    "        # Add batch dimension to the observation tensor\n",
    "        obs_tensor = torch.as_tensor(obs).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        # Use the model's policy to get the value and action.\n",
    "        # For actions, model.predict handles single observations well.\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # Compute the value from the policy.\n",
    "        value_t = model.policy.predict_values(obs_tensor).item()\n",
    "        values.append(value_t)\n",
    "        \n",
    "        # Perform the step in the environment\n",
    "        obs, reward, done, truncated, _ = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        dones.append(done)\n",
    "\n",
    "        if done or truncated:\n",
    "            break\n",
    "\n",
    "    # Add value of the terminal state (0 if done/truncated)\n",
    "    if done or truncated:\n",
    "        terminal_value = 0.0\n",
    "    else:\n",
    "        terminal_obs_tensor = torch.as_tensor(obs).float().unsqueeze(0).to(device)\n",
    "        terminal_value = model.policy.predict_values(terminal_obs_tensor).item()\n",
    "    values.append(terminal_value)\n",
    "\n",
    "    # Compute TD-errors and GAE-like regret score\n",
    "    for t in range(len(rewards)):\n",
    "        delta_t = rewards[t] + gamma * values[t + 1] * (1 - dones[t]) - values[t]\n",
    "        discounted_error = (gamma * lam) ** t * delta_t\n",
    "        regrets.append(max(0, discounted_error))\n",
    "\n",
    "    # Return the maximum positive regret score (or 0 if empty)\n",
    "    return max(regrets) if regrets else 0.0\n",
    "\n",
    "\n",
    "def initialize_ppo(env, learning_rate=1e-4):\n",
    "    return PPO(\n",
    "        \"MlpPolicy\",                    # Multi-layer perceptron policy\n",
    "        env,                            # environment to learn from\n",
    "        verbose=0,                      # Display training output\n",
    "        n_steps=512,                    # Number of steps to run for each environment per update\n",
    "        batch_size=128,                  # Minibatch size for each gradient update\n",
    "        learning_rate=learning_rate,    # Learning rate for optimizer\n",
    "        device=device                   # Use GPU if available\n",
    "    )\n",
    "    \n",
    "# Use vectorized environment\n",
    "def create_vectorized_env(config, n_envs=4, solvable_only=False):\n",
    "    \"\"\"\n",
    "    Create a vectorized environment with n parallel environments.\n",
    "    \"\"\"\n",
    "    return make_vec_env(lambda: MyCustomGrid(config, solvable_only), n_envs=n_envs, vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "\n",
    "\n",
    "def evalute_models(load_dim = -1, grid_size = 6, n_eval_episodes = 5, num_levels_per_difficulty = 10):\n",
    "    \n",
    "    if load_dim > 0:\n",
    "        # Load the models\n",
    "        model_dr = PPO.load(f\"models/dr_model_{load_dim}x{load_dim}\")\n",
    "        model_plr = PPO.load(f\"models/plr_model_{load_dim}x{load_dim}\")\n",
    "        model_accel = PPO.load(f\"models/accel_model_{load_dim}x{load_dim}\")\n",
    "        model_accel_easy = PPO.load(f\"models/accel_model_easy_{load_dim}x{load_dim}\")\n",
    "\n",
    "    # Inseert the models in a dictionary\n",
    "    models = {\"DR\": model_dr, 'PLR': model_plr, 'ACCEL': model_accel, 'ACCEL-EasyStart': model_accel_easy}\n",
    "\n",
    "    # Generate n levels difficulties with increasing complexity, for each level generate m configs\n",
    "    difficulties = 3\n",
    "    num_levels_per_difficulty = num_levels_per_difficulty\n",
    "\n",
    "    levels = []\n",
    "    for i in range(difficulties):\n",
    "        level = []\n",
    "        for _ in range(num_levels_per_difficulty):\n",
    "            cfg = random_config(grid_size, num_blocks=grid_size*(i+1))\n",
    "            #print_level_from_config(cfg, solvable_only=True)\n",
    "            level.append(cfg)\n",
    "        levels.append(level)\n",
    "        \n",
    "    \n",
    "    # Create a dummy config to initialize the vectorized environment\n",
    "    dummy_config = random_config(grid_size)\n",
    "    env = create_vectorized_env(dummy_config, n_envs=4, solvable_only=True)\n",
    "\n",
    "    # Evaluate the model on the generated levels\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        results[model_name] = []\n",
    "        for i, level in enumerate(levels):\n",
    "            print(f\"Evaluating {num_levels_per_difficulty} levels of difficulty {i + 1} with {grid_size*(i+1)} blocks on a {grid_size}x{grid_size} grid for model {model_name}, ratio of blocks to grid size: {grid_size*(i+1) / (grid_size*grid_size):.2f}\")\n",
    "            r = []\n",
    "            for j, cfg in enumerate(level):\n",
    "                # Update the environment with the new config\n",
    "                env.env_method(\"update_config\", cfg)\n",
    "                mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=n_eval_episodes, deterministic=True)\n",
    "                r.append(mean_reward)\n",
    "            results[model_name].append(r)\n",
    "        print()\n",
    "        \n",
    "    # Print mean rewards for each level\n",
    "    for model_name in models.keys():\n",
    "        print(f\"Model: {model_name}\")\n",
    "        for i, level in enumerate(levels):\n",
    "            print(f\"Level {i + 1} - Complexity {grid_size*(i+1)}: {np.mean(results[model_name][i]):.2f}\")\n",
    "        print()\n",
    "    \n",
    "    #Comute the number of xticks based on the number of models\n",
    "    xticks = [i for i in range(1, len(models.keys()) + 1)]\n",
    "\n",
    "    # Boxplot of results, a plot for each level complexity comparing models\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, level in enumerate(levels):\n",
    "        plt.subplot(1, difficulties, i + 1)\n",
    "        plt.boxplot([results[model_name][i] for model_name in models.keys()])\n",
    "        plt.xticks([1,2,3,4], [model_name for model_name in models.keys()])\n",
    "        plt.title(f\"Level {i + 1} - Complexity {grid_size*(i+1)}\")\n",
    "        plt.ylabel(\"Mean Reward\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(f\"plots/boxplot_{load_dim}x{load_dim}.png\")\n",
    "    \n",
    "    \n",
    "def main_accel(total_iterations, replay_prob, train_steps, level_buffer_size,\n",
    "               initial_fill_size, grid_size, n_envs, edit_levels, regret_threshold,\n",
    "               easy_start, domain_randomization, name):\n",
    "    \n",
    "    # Initialize Weights and Biases\n",
    "    wandb.init(project=\"accel\", config=config)\n",
    "    \n",
    "    # Create a level buffer, a personal class to store levels and scores\n",
    "    level_buffer = LevelBuffer(max_size=level_buffer_size)\n",
    "    \n",
    "    # Generate a random configuration {width, height, num_blocks, start_pos, goal_pos}\n",
    "    dummy_config = random_config(grid_size)\n",
    "    \n",
    "    # Create a vectorized environment, so a wrapper for MyCustomGrid that allows interconnection \n",
    "    # between gymnasium and stable-baselines3 to train the model in a vectorized way, since we\n",
    "    # are using DummyVecEnv, it is not true parallelism\n",
    "    vectorized_env = create_vectorized_env(dummy_config, n_envs=n_envs)\n",
    "\n",
    "    # Initialize PPO with vectorized environment\n",
    "    print(\"Initializing student model PPO...\")\n",
    "    student_model = initialize_ppo(vectorized_env)\n",
    "            \n",
    "        \n",
    "\n",
    "    # ====================================================\n",
    "    # Initial buffer fill\n",
    "    # ====================================================\n",
    "    if not domain_randomization:\n",
    "        print(f\"Populating buffer with {initial_fill_size} initial levels with regret > {regret_threshold}...\")\n",
    "        while len(level_buffer.data) < initial_fill_size:\n",
    "            \n",
    "            if easy_start:\n",
    "                cfg = random_config(grid_size, num_blocks=2)\n",
    "            else:\n",
    "                cfg = random_config(grid_size)\n",
    "            \n",
    "            #for monitor in vectorized_env.envs:\n",
    "            #    monitor.env.update_config(cfg)\n",
    "            \n",
    "            vectorized_env.env_method(\"update_config\", cfg)\n",
    "            \n",
    "            student_model.learn(total_timesteps=100)\n",
    "            \n",
    "            regret = calculate_regret_gae(MyCustomGrid(cfg), student_model, max_steps=1000, gamma=0.99, lam=0.95)\n",
    "\n",
    "            # Skip levels with low regret\n",
    "            if regret < regret_threshold: continue\n",
    "\n",
    "            level_buffer.add(cfg, regret)\n",
    "\n",
    "    # ====================================================\n",
    "    # Main ACCEL loop\n",
    "    # ====================================================\n",
    "    \n",
    "    iteration_regrets = []\n",
    "    iteration, skipped = 0, 0\n",
    "    \n",
    "    print(\"\\nMain training loop...\")\n",
    "    while iteration < total_iterations + skipped:\n",
    "        \n",
    "        print(f\"\\n=== ITERATION {iteration + 1}/{total_iterations + skipped} SKIPPED: {skipped} ===\")\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        if domain_randomization:\n",
    "            cfg = random_config(grid_size)\n",
    "            vectorized_env.env_method(\"update_config\", cfg)\n",
    "            student_model.learn(total_timesteps=train_steps)\n",
    "            regret = calculate_regret_gae(MyCustomGrid(cfg), student_model, max_steps=1000, gamma=0.99, lam=0.95)\n",
    "            print(f\"Regret for current level: {regret}, buffer size: {len(level_buffer.data)}\")\n",
    "            iteration_regrets.append(regret)\n",
    "            \n",
    "            # if regret is below threshold, skip\n",
    "            if regret <= regret_threshold:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # Decide whether to replay or generate a new level\n",
    "        use_replay = np.random.rand() < replay_prob\n",
    "\n",
    "        if not use_replay or len(level_buffer.data) == 0:\n",
    "            # Create a new random level\n",
    "            cfg = random_config(grid_size)\n",
    "            print(\"Generated new random level:\", cfg)\n",
    "        else:\n",
    "            # Sample a level from the buffer\n",
    "            cfg = level_buffer.sample_config()\n",
    "            print(\"Sampled level from buffer:\", cfg)\n",
    "            \n",
    "        # Update the vectorized environment with the selected config and train the model\n",
    "        #for monitor in vectorized_env.envs:\n",
    "        #    monitor.env.update_config(cfg)\n",
    "        \n",
    "        vectorized_env.env_method(\"update_config\", cfg)\n",
    "        \n",
    "        student_model.learn(total_timesteps=train_steps)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"iteration\": iteration,\n",
    "            \"regret_score\": regret,\n",
    "            \"regret_threshold\": regret_threshold,\n",
    "            \"buffer_size\": len(level_buffer.data),\n",
    "            \"value_loss\": student_model.logger.name_to_value[\"train/value_loss\"],\n",
    "            \"entropy_loss\": student_model.logger.name_to_value[\"train/entropy_loss\"],\n",
    "            \"policy_loss\": student_model.logger.name_to_value[\"train/policy_loss\"],\n",
    "        })\n",
    "\n",
    "        if use_replay and edit_levels:\n",
    "            # Edit the level and calculate regret\n",
    "            cfg = edit_config(cfg)\n",
    "            print(\"Edited level to:\", cfg)\n",
    "\n",
    "        regret = calculate_regret_gae(MyCustomGrid(cfg), student_model, max_steps=1000, gamma=0.99, lam=0.95)\n",
    "        \n",
    "        if regret <= regret_threshold:\n",
    "            print(f\"Regret for current level is {regret:.5f} <= threshold {regret_threshold:.5f}. Skipping...\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        print(f\"Regret for current level: {regret}, buffer size: {len(level_buffer.data)}\")\n",
    "        level_buffer.add(cfg, regret)\n",
    "        iteration_regrets.append(regret)\n",
    "        \n",
    "        # Increase the regret threshold slightly\n",
    "        regret_threshold += 0.0001\n",
    "        \n",
    "    \n",
    "    # Plot and display the progress\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(iteration_regrets, marker='o')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Regret\")\n",
    "    plt.title(\"Regret Progress during Training\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(f\"regret_progress_{name}_{grid_size}x{grid_size}.png\")\n",
    "    \n",
    "    \n",
    "    print(\"\\nDone. Final buffer size:\", len(level_buffer.data))\n",
    "    print(\"Top-5 hardest levels (config, regret):\")\n",
    "    level_buffer.data.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i, (cfg, sc) in enumerate(level_buffer.data[:5]):\n",
    "        print(f\"{i + 1}. regret={sc:.5f}, config={cfg}\")\n",
    "        #print_level_from_config(cfg)\n",
    "        \n",
    "    print(\"Top-5 easiest levels (config, regret):\")\n",
    "    level_buffer.data.sort(key=lambda x: x[1])\n",
    "    for i, (cfg, sc) in enumerate(level_buffer.data[:5]):\n",
    "        print(f\"{i + 1}. regret={sc:.5f}, config={cfg}\")\n",
    "        #print_level_from_config(cfg)\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    # Save the model\n",
    "    student_model.save(f\"models/{name}\")\n",
    "\n",
    "    return student_model\n",
    "\n",
    "\n",
    "\n",
    "def calculate_regret_gae_vectorized(vec_env, model, max_steps, gamma, lam):\n",
    "    \"\"\"\n",
    "    Compute GAE-based regrets for each sub-environment in vec_env, in parallel.\n",
    "\n",
    "    - vec_env: A vectorized environment with n_envs sub-envs, each configured differently.\n",
    "    - model: A trained (or partially trained) stable-baselines PPO model.\n",
    "    - max_steps: Maximum steps to roll out each sub-environment.\n",
    "    - gamma, lam: Discount and GAE lambda for advantage/td-error calculation.\n",
    "    \n",
    "    Returns: A list of regrets, one for each sub-environment.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_envs = vec_env.num_envs\n",
    "\n",
    "    # Lists to store per-environment roll data\n",
    "    all_rewards = [[] for _ in range(n_envs)]\n",
    "    all_values = [[] for _ in range(n_envs)]\n",
    "    all_dones = [[] for _ in range(n_envs)]\n",
    "\n",
    "    # Initialize observations\n",
    "    obs_array = vec_env.reset()\n",
    "    obs_tensor = torch.as_tensor(obs_array, dtype=torch.float32, device=device)\n",
    "\n",
    "    # Track \"still alive\" sub-envs\n",
    "    done_flags = [False] * n_envs\n",
    "\n",
    "    # Roll out the environments in parallel\n",
    "    for step in range(max_steps):\n",
    "        # Stop if all environments are finished\n",
    "        if all(done_flags):\n",
    "            break\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # model.predict() can handle vectorized obs of shape (n_envs, obs_dim,...)\n",
    "            actions, _ = model.predict(obs_array, deterministic=True)\n",
    "            # Predict values for GAE computation\n",
    "            values_t = model.policy.predict_values(obs_tensor).squeeze(dim=-1)  # shape: (n_envs,)\n",
    "\n",
    "        # Step all environments in parallel\n",
    "        new_obs_array, rewards, dones, infos = vec_env.step(actions)\n",
    "\n",
    "        # Store rewards, values, and done flags\n",
    "        for i in range(n_envs):\n",
    "            if not done_flags[i]: \n",
    "                all_rewards[i].append(rewards[i])\n",
    "                all_values[i].append(values_t[i].item())\n",
    "                all_dones[i].append(dones[i])\n",
    "\n",
    "        # Mark newly finished envs\n",
    "        done_flags = [done_flags[i] or dones[i] for i in range(n_envs)]\n",
    "\n",
    "        # Update observations\n",
    "        obs_array = new_obs_array\n",
    "        obs_tensor = torch.as_tensor(obs_array, dtype=torch.float32, device=device)\n",
    "\n",
    "    # Compute terminal values (if environment ended early, assume terminal_value = 0)\n",
    "    with torch.no_grad():\n",
    "        terminal_values = model.policy.predict_values(obs_tensor).cpu().numpy().flatten()  # shape: (n_envs,)\n",
    "\n",
    "    # GAE-based regret computation\n",
    "    regrets = []\n",
    "    for i in range(n_envs):\n",
    "        rewards_i = all_rewards[i]\n",
    "        values_i = all_values[i]\n",
    "        dones_i = all_dones[i]\n",
    "\n",
    "        if not rewards_i:\n",
    "            # No trajectory (e.g., env ended at t=0)\n",
    "            regrets.append(0.0)\n",
    "            continue\n",
    "\n",
    "        # Set terminal value\n",
    "        last_val = 0.0 if dones_i[-1] else float(terminal_values[i])\n",
    "        values_i.append(last_val)\n",
    "\n",
    "        # Compute GAE-based regret: sum of positive deltas\n",
    "        env_regrets = []\n",
    "        discount_factor = 1.0  # Tracks (gamma * lam)^t accumulation\n",
    "\n",
    "        for t in range(len(rewards_i)):\n",
    "            delta_t = rewards_i[t] + gamma * values_i[t + 1] * (1 - dones_i[t]) - values_i[t]\n",
    "            discounted_delta = discount_factor * delta_t\n",
    "            env_regrets.append(max(discounted_delta, 0.0))\n",
    "\n",
    "            # Update discount factor for next step\n",
    "            discount_factor *= gamma * lam\n",
    "\n",
    "        regrets.append(max(env_regrets) if env_regrets else 0.0)\n",
    "\n",
    "    return regrets\n",
    "\n",
    "\n",
    "\n",
    "def test_model(model, config, gif_path=\"level.gif\"):\n",
    "    \"\"\"Evaluate a model on a given environment instance.\"\"\"\n",
    "    env = MyCustomGrid(config, render_mode='rgb_array', solvable_only=True)\n",
    "    obs, _ = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    total_reward = 0\n",
    "    i = 0\n",
    "\n",
    "    frames = []  # List to store frames\n",
    "\n",
    "    # Continue until either terminated or truncated is True\n",
    "    while not (terminated or truncated):\n",
    "        frame = env.render()  # Capture frame as an image\n",
    "        frames.append(Image.fromarray(frame))  # Convert to PIL image and store\n",
    "        \n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            break\n",
    "    \n",
    "    # Add to the gif also the last frame\n",
    "    frame = env.render()\n",
    "    frames.append(Image.fromarray(frame))\n",
    "\n",
    "    # Save frames as a GIF\n",
    "    if frames:\n",
    "        frames[0].save(\n",
    "            gif_path, save_all=True, append_images=frames[1:], duration=500, loop=0\n",
    "        )\n",
    "    return total_reward  # Do not close env here, as we reuse it\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 4. Main ACCEL Loop with Parallel Environments\n",
    "# ====================================================\n",
    "\n",
    "\n",
    "def main_accel_parallel(total_iterations, replay_prob, train_steps, level_buffer_size,\n",
    "               initial_fill_size, grid_size, n_envs, edit_levels, regret_threshold,\n",
    "               easy_start, domain_randomization, name):\n",
    "    \n",
    "    # Initialize Weights and Biases\n",
    "    wandb.init(project=\"accel\", config=config)\n",
    "    \n",
    "    # Create a level buffer, a personal class to store levels and scores\n",
    "    level_buffer = LevelBuffer(max_size=level_buffer_size)\n",
    "    \n",
    "    # Generate a random configuration {width, height, num_blocks, start_pos, goal_pos}\n",
    "    dummy_config = random_config(grid_size)\n",
    "    \n",
    "    # Create a vectorized environment, so a wrapper for MyCustomGrid that allows interconnection \n",
    "    # between gymnasium and stable-baselines3 to train the model in a vectorized way, since we\n",
    "    # are using DummyVecEnv, it is not true parallelism\n",
    "    vectorized_env = create_vectorized_env(dummy_config, n_envs=n_envs)\n",
    "\n",
    "    # Initialize PPO with vectorized environment\n",
    "    print(\"Initializing student model PPO...\")\n",
    "    student_model = initialize_ppo(vectorized_env)\n",
    "            \n",
    "        \n",
    "\n",
    "    # ====================================================\n",
    "    # Initial buffer fill\n",
    "    # ====================================================\n",
    "    if not domain_randomization:\n",
    "        print(f\"Populating buffer with {initial_fill_size} initial levels with regret > {regret_threshold}...\")\n",
    "        while len(level_buffer.data) < initial_fill_size:\n",
    "            \n",
    "            # Generate n_envs configs\n",
    "            configs = []\n",
    "            for _ in range(n_envs):\n",
    "                if easy_start:\n",
    "                    cfg = random_config(grid_size, num_blocks=2, seed=42+len(level_buffer.data))\n",
    "                else:\n",
    "                    cfg = random_config(grid_size, seed=42+len(level_buffer.data))\n",
    "                configs.append(cfg)\n",
    "\n",
    "            # Set every environment with a different config\n",
    "            for i in range(n_envs):\n",
    "                vectorized_env.env_method(\"update_config\", configs[i], indices=i)\n",
    "                \n",
    "            # Train the model using the vectorized environment            \n",
    "            student_model.learn(total_timesteps=train_steps)\n",
    "            \n",
    "            # Calculate regret for each environment\n",
    "            regrets = calculate_regret_gae_vectorized(vectorized_env, student_model, max_steps=1000, gamma=0.99, lam=0.95)\n",
    "            \n",
    "            # Add the configs with regret > threshold to the buffer\n",
    "            for i in range(n_envs):\n",
    "                cfg = configs[i]\n",
    "                regret = regrets[i]\n",
    "                if regret < regret_threshold: continue\n",
    "                level_buffer.add(cfg, regret)\n",
    "\n",
    "    # ====================================================\n",
    "    # Main ACCEL loop\n",
    "    # ====================================================\n",
    "    \n",
    "    iteration_regrets = []\n",
    "    iteration, skipped = 0, 0\n",
    "    \n",
    "    print(\"\\nMain training loop...\")\n",
    "    while iteration < total_iterations + skipped:\n",
    "        \n",
    "        print(f\"\\n=== ITERATION {iteration + 1}/{total_iterations + skipped} SKIPPED: {skipped} ===\")\n",
    "        \n",
    "        # every 30 iterations, we will evaluate the model\n",
    "        if iteration % 30 == 0:\n",
    "            print(\"Evaluating model...\")\n",
    "            tot_rew = 0\n",
    "            for i in range (30):\n",
    "                testino = random_config(grid_size, seed=42+iteration)\n",
    "                rew = test_model(student_model, testino, gif_path=f\"gifs/level_{i}_dr.gif\")\n",
    "                tot_rew += rew\n",
    "            print(f\"Average reward: {tot_rew/30}\")\n",
    "        \n",
    "        iteration += n_envs\n",
    "        \n",
    "        if domain_randomization:\n",
    "            # Create n_envs random configs\n",
    "            configs = []\n",
    "            for _ in range(n_envs):\n",
    "                cfg = random_config(grid_size, seed=42+iteration)\n",
    "                configs.append(cfg)\n",
    "            \n",
    "            # Set every environment with a different config\n",
    "            for i in range(n_envs):\n",
    "                vectorized_env.env_method(\"update_config\", configs[i], indices=i)\n",
    "\n",
    "            # Train the model using the vectorized environment\n",
    "            student_model.learn(total_timesteps=train_steps)\n",
    "            \n",
    "            # Calculate regret for each environment\n",
    "            regrets = calculate_regret_gae_vectorized(vectorized_env, student_model, max_steps=2048, gamma=0.99, lam=0.95)\n",
    "            \n",
    "            \n",
    "            for i in range(n_envs):\n",
    "                cfg = configs[i]\n",
    "                regret = regrets[i]\n",
    "                #print(f\"Regret for current level: {regret}, buffer size: {len(level_buffer.data)}\")\n",
    "                iteration_regrets.append(regret)\n",
    "                \n",
    "                # if regret is below threshold, skip\n",
    "                if regret <= regret_threshold:\n",
    "                    print(f\"Regret for current level is {regret:.5f} <= threshold {regret_threshold:.5f}. Skipping...\")\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "            \n",
    "            if iteration >= total_iterations + skipped:\n",
    "                return student_model\n",
    "        \n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Decide whether to replay or generate a new level for ench n_envs environments\n",
    "        use_replay = [np.random.rand() < replay_prob for _ in range(n_envs)]\n",
    "        configs = []\n",
    "        for replay_decision in use_replay:\n",
    "            if not replay_decision or len(level_buffer.data) == 0:\n",
    "                # Create a new random level\n",
    "                cfg = random_config(grid_size, seed=42+iteration)\n",
    "                print(\"Generated new random level:\", cfg)\n",
    "            else:\n",
    "                # Sample a level from the buffer\n",
    "                cfg = level_buffer.sample_config()\n",
    "                print(\"Sampled level from buffer:\", cfg)\n",
    "            configs.append(cfg)\n",
    "        \n",
    "        for i in range(n_envs):\n",
    "            # Update the vectorized environment with the selected config and train the model\n",
    "            vectorized_env.env_method(\"update_config\", configs[i], indices=i)\n",
    "        \n",
    "        \n",
    "        student_model.learn(total_timesteps=train_steps)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"iteration\": iteration,\n",
    "            \"regret_score\": regret,\n",
    "            \"regret_threshold\": regret_threshold,\n",
    "            \"buffer_size\": len(level_buffer.data),\n",
    "            \"value_loss\": student_model.logger.name_to_value[\"train/value_loss\"],\n",
    "            \"entropy_loss\": student_model.logger.name_to_value[\"train/entropy_loss\"],\n",
    "            \"policy_loss\": student_model.logger.name_to_value[\"train/policy_loss\"],\n",
    "        })\n",
    "\n",
    "        for i in range(n_envs):\n",
    "            if use_replay[i] and edit_levels:\n",
    "                configs[i] = edit_config(configs[i])\n",
    "                print(\"Edited level to:\", configs[i])\n",
    "\n",
    "\n",
    "        regrets = calculate_regret_gae_vectorized(vectorized_env, student_model, max_steps=2048, gamma=0.99, lam=0.95)\n",
    "        \n",
    "        # Pair each configuration with its computed regret\n",
    "        results = list(zip(configs, regrets))\n",
    "        for cfg_i, regret in results:\n",
    "            if regret <= regret_threshold:\n",
    "                print(f\"Regret for current level is {regret:.5f} <= threshold {regret_threshold:.5f}. Skipping...\")\n",
    "                skipped += 1\n",
    "                iteration_regrets.append(regret)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Regret for current level: {regret}, buffer size: {len(level_buffer.data)}\")\n",
    "                iteration_regrets.append(regret)\n",
    "                level_buffer.add(cfg_i, regret)\n",
    "\n",
    "        \n",
    "        # Increase the regret threshold slightly\n",
    "        #regret_threshold += 0.0001\n",
    "        \n",
    "    # close the environment\n",
    "    vectorized_env.close()\n",
    "    \n",
    "    # Plot and display the progress\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(iteration_regrets, marker='o')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Regret\")\n",
    "    plt.title(\"Regret Progress during Training\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(f\"plots/regret_progress_{name}_{grid_size}x{grid_size}.png\")\n",
    "    \n",
    "    \n",
    "    print(\"\\nDone. Final buffer size:\", len(level_buffer.data))\n",
    "    print(\"Top-5 hardest levels (config, regret):\")\n",
    "    level_buffer.data.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i, (cfg, sc) in enumerate(level_buffer.data[:5]):\n",
    "        print(f\"{i + 1}. regret={sc:.5f}, config={cfg}\")\n",
    "        #print_level_from_config(cfg)\n",
    "        \n",
    "    print(\"Top-5 easiest levels (config, regret):\")\n",
    "    level_buffer.data.sort(key=lambda x: x[1])\n",
    "    for i, (cfg, sc) in enumerate(level_buffer.data[:5]):\n",
    "        print(f\"{i + 1}. regret={sc:.5f}, config={cfg}\")\n",
    "        #print_level_from_config(cfg)\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    # Save the model\n",
    "    student_model.save(f\"models/{name}\")\n",
    "    print(f\"Model saved as models/{name}\")\n",
    "\n",
    "    return student_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Domain Randomization with config: {'name': 'dr_model_8x8', 'grid_size': 8, 'total_iterations': 50, 'train_steps': 12288, 'replay_prob': 0.7, 'level_buffer_size': 128, 'initial_fill_size': 64, 'regret_threshold': 0.0, 'n_envs': 24, 'edit_levels': False, 'easy_start': False, 'domain_randomization': True}\n",
      "Initializing student model PPO...\n",
      "\n",
      "Main training loop...\n",
      "\n",
      "=== ITERATION 1/50 SKIPPED: 0 ===\n",
      "Evaluating model...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Average reward: 0.0\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "\n",
      "=== ITERATION 25/63 SKIPPED: 13 ===\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "\n",
      "=== ITERATION 49/76 SKIPPED: 26 ===\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "\n",
      "=== ITERATION 73/95 SKIPPED: 45 ===\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "\n",
      "=== ITERATION 97/103 SKIPPED: 53 ===\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "\n",
      "Running PLR with config: {'name': 'plr_model_8x8', 'grid_size': 8, 'total_iterations': 50, 'train_steps': 12288, 'replay_prob': 0.7, 'level_buffer_size': 128, 'initial_fill_size': 64, 'regret_threshold': 0.0, 'n_envs': 24, 'edit_levels': False, 'easy_start': False, 'domain_randomization': False}\n",
      "Initializing student model PPO...\n",
      "Populating buffer with 64 initial levels with regret > 0.0...\n",
      "\n",
      "Main training loop...\n",
      "\n",
      "=== ITERATION 1/50 SKIPPED: 0 ===\n",
      "Evaluating model...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Average reward: 0.0\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 15, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 23, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 8, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 12, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.05430431349456311, buffer size: 72\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.03464655667543412, buffer size: 73\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.021017881444506347, buffer size: 74\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.006766364620998501, buffer size: 75\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.006766364620998501, buffer size: 76\n",
      "Regret for current level: 0.043412541637589064, buffer size: 77\n",
      "Regret for current level: 0.06776496328413487, buffer size: 78\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.033972468901947134, buffer size: 79\n",
      "Regret for current level: 0.051845955394506454, buffer size: 80\n",
      "Regret for current level: 0.01940025298856199, buffer size: 81\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.023076663538813588, buffer size: 82\n",
      "Regret for current level: 0.006766364620998501, buffer size: 83\n",
      "\n",
      "=== ITERATION 25/62 SKIPPED: 12 ===\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 13, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 8, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 20, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 13, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.0007203086547087879, buffer size: 84\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.0556274425983429, buffer size: 85\n",
      "Regret for current level: 0.11360842674970627, buffer size: 86\n",
      "Regret for current level: 0.05445720083216205, buffer size: 87\n",
      "Regret for current level: 0.0010718304282054305, buffer size: 88\n",
      "Regret for current level: 0.13610381225282328, buffer size: 89\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.04379888758063316, buffer size: 90\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.017917168237036093, buffer size: 91\n",
      "Regret for current level: 0.0020784331392496823, buffer size: 92\n",
      "Regret for current level: 0.022914415374398228, buffer size: 93\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.0657930038869381, buffer size: 94\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.1025000280793011, buffer size: 95\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.05150777725018452, buffer size: 96\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "\n",
      "=== ITERATION 49/73 SKIPPED: 23 ===\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 22, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 21, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 8, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 21, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 15, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 12, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Regret for current level: 0.09124891620274633, buffer size: 97\n",
      "Regret for current level: 0.06686522483825683, buffer size: 98\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 6.57042767852542e-05, buffer size: 99\n",
      "Regret for current level: 0.07142000295221805, buffer size: 100\n",
      "Regret for current level: 0.006743121773544698, buffer size: 101\n",
      "Regret for current level: 0.012023520125076174, buffer size: 102\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.10993539921939373, buffer size: 103\n",
      "Regret for current level: 0.07551956916321069, buffer size: 104\n",
      "Regret for current level: 0.08181755367666482, buffer size: 105\n",
      "Regret for current level: 0.00018412172794341972, buffer size: 106\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.03445269296062179, buffer size: 107\n",
      "Regret for current level: 0.01030832010321319, buffer size: 108\n",
      "Regret for current level: 0.01030832010321319, buffer size: 109\n",
      "Regret for current level: 0.015846984162926667, buffer size: 110\n",
      "Regret for current level: 0.031543546634439826, buffer size: 111\n",
      "Regret for current level: 0.19988639175891876, buffer size: 112\n",
      "Regret for current level: 0.16432880766689778, buffer size: 113\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.18547463697832078, buffer size: 114\n",
      "\n",
      "=== ITERATION 73/79 SKIPPED: 29 ===\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 21, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 15, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 1, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 15, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Regret for current level: 0.04844294188195176, buffer size: 115\n",
      "Regret for current level: 0.1120527759566903, buffer size: 116\n",
      "Regret for current level: 0.13353086072951553, buffer size: 117\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.0005591458082199116, buffer size: 118\n",
      "Regret for current level: 0.12352490614380687, buffer size: 119\n",
      "Regret for current level: 0.17280756103686254, buffer size: 120\n",
      "Regret for current level: 0.0028023980371654038, buffer size: 121\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.0028023980371654038, buffer size: 122\n",
      "Regret for current level: 0.12917745910037312, buffer size: 123\n",
      "Regret for current level: 0.00032666586339473447, buffer size: 124\n",
      "Regret for current level: 0.00025216458365321173, buffer size: 125\n",
      "Regret for current level: 0.07791722838945686, buffer size: 126\n",
      "Regret for current level: 0.29550322920084, buffer size: 127\n",
      "Regret for current level: 0.0028023980371654038, buffer size: 128\n",
      "Regret for current level: 0.00038998393526505436, buffer size: 128\n",
      "Regret for current level: 0.21987649063870313, buffer size: 128\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.0004117941256240039, buffer size: 128\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done. Final buffer size: 128\n",
      "Top-5 hardest levels (config, regret):\n",
      "1. regret=0.29550, config={'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "2. regret=0.21988, config={'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "3. regret=0.19989, config={'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "4. regret=0.18547, config={'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "5. regret=0.17281, config={'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Top-5 easiest levels (config, regret):\n",
      "1. regret=0.00000, config={'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "2. regret=0.00000, config={'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "3. regret=0.00000, config={'width': 8, 'height': 8, 'num_blocks': 8, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "4. regret=0.00000, config={'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "5. regret=0.00000, config={'width': 8, 'height': 8, 'num_blocks': 20, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as models/plr_model_8x8\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "\n",
      "Running ACCEL with config: {'name': 'accel_model_8x8', 'grid_size': 8, 'total_iterations': 50, 'train_steps': 12288, 'replay_prob': 0.7, 'level_buffer_size': 128, 'initial_fill_size': 64, 'regret_threshold': 0.0, 'n_envs': 24, 'edit_levels': True, 'easy_start': False, 'domain_randomization': False}\n",
      "Initializing student model PPO...\n",
      "Populating buffer with 64 initial levels with regret > 0.0...\n",
      "\n",
      "Main training loop...\n",
      "\n",
      "=== ITERATION 1/50 SKIPPED: 0 ===\n",
      "Evaluating model...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Re-randomizing start and goal positions...\n",
      "Average reward: 0.0\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 22, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 21, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 13, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 21, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 13, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 1, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 12, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 24, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 20, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 21, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 12, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 24, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 22, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 20, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 23, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 20, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 13, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.012082157203328786, buffer size: 72\n",
      "Regret for current level: 0.010156158655881882, buffer size: 73\n",
      "Regret for current level: 0.05877750687301159, buffer size: 74\n",
      "Regret for current level: 0.0695878824378381, buffer size: 75\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.006392293446203692, buffer size: 76\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.008287756387144327, buffer size: 77\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.01886816085330421, buffer size: 78\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.0511589653044939, buffer size: 79\n",
      "Regret for current level: 0.00023436060175299755, buffer size: 80\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.03290382148261115, buffer size: 81\n",
      "\n",
      "=== ITERATION 25/64 SKIPPED: 14 ===\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 21, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 8, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 6, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 13, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 13, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 8, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 23, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 22, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 9, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 23, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 8, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 15, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 21, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 6, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 6, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 24, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 20, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Regret for current level: 7.0373006165028e-05, buffer size: 82\n",
      "Regret for current level: 0.08921018635854125, buffer size: 83\n",
      "Regret for current level: 0.02908130729570985, buffer size: 84\n",
      "Regret for current level: 0.0029866607859730734, buffer size: 85\n",
      "Regret for current level: 0.07355215602915734, buffer size: 86\n",
      "Regret for current level: 0.00014865112692117588, buffer size: 87\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.00021411113440990628, buffer size: 88\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.00017092340511269853, buffer size: 89\n",
      "Regret for current level: 0.00016075346250849298, buffer size: 90\n",
      "Regret for current level: 0.02908130729570985, buffer size: 91\n",
      "Regret for current level: 0.043503142111003396, buffer size: 92\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.03764939802467823, buffer size: 93\n",
      "Regret for current level: 0.02000034410678374, buffer size: 94\n",
      "Regret for current level: 0.05396528304735315, buffer size: 95\n",
      "Regret for current level: 0.00018173674121499048, buffer size: 96\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.010502324514091013, buffer size: 97\n",
      "Regret for current level: 0.04289209476898424, buffer size: 98\n",
      "Regret for current level: 0.05745296802643687, buffer size: 99\n",
      "\n",
      "=== ITERATION 49/70 SKIPPED: 20 ===\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 1, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 22, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 13, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 8, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 12, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 13, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 8, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (1, 6), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 114}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 6, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 22, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 12, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 21, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 15, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 12, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 20, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 21, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 7, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 13, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 23, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Regret for current level: 0.0035095272841863335, buffer size: 100\n",
      "Regret for current level: 0.06845704868435859, buffer size: 101\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.00017004208311438573, buffer size: 102\n",
      "Regret for current level: 0.0001792475767433653, buffer size: 103\n",
      "Regret for current level: 0.08518191140145064, buffer size: 104\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 4.236105014570083e-06, buffer size: 105\n",
      "Regret for current level: 0.033223582534119486, buffer size: 106\n",
      "Regret for current level: 0.10711743881227448, buffer size: 107\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.00021006271243095495, buffer size: 108\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.00021006271243095495, buffer size: 109\n",
      "Regret for current level: 0.001688238269984723, buffer size: 110\n",
      "Regret for current level: 7.637314498424533e-05, buffer size: 111\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.05591400298889727, buffer size: 112\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.049131885458557734, buffer size: 113\n",
      "Regret for current level: 0.05769094860173858, buffer size: 114\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "\n",
      "=== ITERATION 73/79 SKIPPED: 29 ===\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 15, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 20, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 6, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': False, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 12, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 2, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 22, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': False, 'seed_val': 90}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 10, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 15, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 16, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Generated new random level: {'width': 8, 'height': 8, 'num_blocks': 12, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "Sampled level from buffer: {'width': 8, 'height': 8, 'num_blocks': 5, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 12, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 7, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 15, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 22, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 3, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 8, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 7, 'start_pos': (5, 1), 'goal_pos': (3, 4), 'edited': True, 'seed_val': 90}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 12, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 13, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Edited level to: {'width': 8, 'height': 8, 'num_blocks': 6, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.04114533128216863, buffer size: 115\n",
      "Regret for current level: 0.0003287913883477447, buffer size: 116\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.00012949060262180799, buffer size: 117\n",
      "Regret for current level: 0.2793599434050545, buffer size: 118\n",
      "Regret for current level: 0.06028143793344498, buffer size: 119\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.022024960964918128, buffer size: 120\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.00022497441080398883, buffer size: 121\n",
      "Regret for current level: 0.08634526588022709, buffer size: 122\n",
      "Regret for current level: 0.10588139973580837, buffer size: 123\n",
      "Regret for current level: 0.05882876969873905, buffer size: 124\n",
      "Regret for current level: 0.019921000748872757, buffer size: 125\n",
      "Regret for current level: 0.027538743633776903, buffer size: 126\n",
      "Regret for current level: 0.21143325582146644, buffer size: 127\n",
      "Regret for current level: 0.05513656058022326, buffer size: 128\n",
      "Regret for current level: 0.0880838063849985, buffer size: 128\n",
      "Regret for current level: 0.08294454476315528, buffer size: 128\n",
      "Regret for current level: 0.0003287913883477447, buffer size: 128\n",
      "Regret for current level is 0.00000 <= threshold 0.00000. Skipping...\n",
      "Regret for current level: 0.07803860612213612, buffer size: 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done. Final buffer size: 128\n",
      "Top-5 hardest levels (config, regret):\n",
      "1. regret=0.27936, config={'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "2. regret=0.21143, config={'width': 8, 'height': 8, 'num_blocks': 17, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "3. regret=0.10712, config={'width': 8, 'height': 8, 'num_blocks': 14, 'start_pos': (5, 2), 'goal_pos': (6, 6), 'edited': True, 'seed_val': 66}\n",
      "4. regret=0.10588, config={'width': 8, 'height': 8, 'num_blocks': 4, 'start_pos': (5, 5), 'goal_pos': (4, 4), 'edited': False, 'seed_val': 138}\n",
      "5. regret=0.08921, config={'width': 8, 'height': 8, 'num_blocks': 11, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': True, 'seed_val': 42}\n",
      "Top-5 easiest levels (config, regret):\n",
      "1. regret=0.00000, config={'width': 8, 'height': 8, 'num_blocks': 21, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "2. regret=0.00000, config={'width': 8, 'height': 8, 'num_blocks': 18, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "3. regret=0.00000, config={'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "4. regret=0.00000, config={'width': 8, 'height': 8, 'num_blocks': 19, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n",
      "5. regret=0.00000, config={'width': 8, 'height': 8, 'num_blocks': 23, 'start_pos': (3, 4), 'goal_pos': (5, 1), 'edited': False, 'seed_val': 42}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as models/accel_model_8x8\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "\n",
      "Running ACCEL with easy start with config: {'name': 'accel_model_easy_8x8', 'grid_size': 8, 'total_iterations': 50, 'train_steps': 12288, 'replay_prob': 0.7, 'level_buffer_size': 128, 'initial_fill_size': 64, 'regret_threshold': 0.0, 'n_envs': 24, 'edit_levels': True, 'easy_start': True, 'domain_randomization': False}\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "        \n",
    "    wandb.finish()\n",
    "        \n",
    "    config = {\n",
    "            \"name\": \"model\",\n",
    "            \"grid_size\": 8,\n",
    "            \n",
    "            \"total_iterations\": 50,\n",
    "            \"train_steps\": 512*24,            # Number of steps to train the model for each level\n",
    "\n",
    "            \"replay_prob\": 0.7,            # Probability of replaying a level and editing it vs. generating a new one\n",
    "            \"level_buffer_size\": 128,       # Maximum number of levels to store in the buffer\n",
    "            \"initial_fill_size\": 64,       # Number of levels to pre-fill the buffer with\n",
    "            \"regret_threshold\": 0.00,      # Minimum regret threshold to consider a level for the buffer\n",
    "            \n",
    "            \"n_envs\": 24,                   # Number of parallel environments to use for training\n",
    "            \n",
    "            \"edit_levels\": True,           # Whether to edit levels during training i.e. ACCEL or PLR\n",
    "            \"easy_start\": True,            # Whether to fill the buffer with easy levels first i.e. minimum number of blocks\n",
    "            \"domain_randomization\": False, # Whether to use domain randomization\n",
    "    \n",
    "        }\n",
    "\n",
    "\n",
    "    config[\"name\"] = f\"dr_model_{config['grid_size']}x{config['grid_size']}\"\n",
    "    config[\"domain_randomization\"] = True\n",
    "    config[\"edit_levels\"] = False\n",
    "    config[\"easy_start\"] = False\n",
    "    print(f\"Running Domain Randomization with config: {config}\")\n",
    "    #model_dr = main_accel(**config)\n",
    "    model_dr = main_accel_parallel(**config)\n",
    "        \n",
    "    print(\"\\n\\n============================================\\n\\n\")\n",
    "    \n",
    "    config[\"name\"] = f\"plr_model_{config['grid_size']}x{config['grid_size']}\"\n",
    "    config[\"domain_randomization\"] = False\n",
    "    config[\"edit_levels\"] = False\n",
    "    config[\"easy_start\"] = False\n",
    "    print(f\"Running PLR with config: {config}\")\n",
    "    #model_plr = main_accel(**config)\n",
    "    model_plr = main_accel_parallel(**config)\n",
    "\n",
    "    print(\"\\n\\n============================================\\n\\n\")\n",
    "\n",
    "\n",
    "    config[\"name\"] = f\"accel_model_{config['grid_size']}x{config['grid_size']}\"\n",
    "    config[\"domain_randomization\"] = False\n",
    "    config[\"edit_levels\"] = True\n",
    "    config[\"easy_start\"] = False\n",
    "    print(f\"Running ACCEL with config: {config}\")\n",
    "    #model_accel = main_accel(**config)\n",
    "    model_accel = main_accel_parallel(**config)\n",
    "\n",
    "    print(\"\\n\\n============================================\\n\\n\")\n",
    "    \n",
    "    config[\"name\"] = f\"accel_model_easy_{config['grid_size']}x{config['grid_size']}\"\n",
    "    config[\"domain_randomization\"] = False\n",
    "    config[\"edit_levels\"] = True\n",
    "    config[\"easy_start\"] = True\n",
    "    print(f\"Running ACCEL with easy start with config: {config}\")\n",
    "    #model_accel_easy = main_accel(**config)\n",
    "    #model_accel_easy = main_accel_parallel(**config)\n",
    "    \n",
    "    print(\"\\n\\n============================================\\n\\n\")\n",
    "\n",
    "    # Evaluate the models\n",
    "    #evalute_models(load_dim = config[\"grid_size\"], grid_size = config[\"grid_size\"], n_eval_episodes = 5, num_levels_per_difficulty = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evalute_models(load_dim=8, grid_size=12, n_eval_episodes=10, num_levels_per_difficulty=30)\n",
    "\n",
    "\"\"\"\n",
    "models = {\n",
    "    \"DR\": model_dr,\n",
    "    \"PLR\": model_plr,\n",
    "    \"ACCEL\": model_accel,\n",
    "    \"ACCEL-EasyStart\": model_accel_easy\n",
    "}\n",
    "    \n",
    "# Test the models on previously evaluated levels\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Testing model {model_name} on previously evaluated levels...\")\n",
    "    for i, level in enumerate(levels):\n",
    "        print(f\"Level {i + 1} - Complexity {(i+2)**2}:\")\n",
    "        for j, cfg in enumerate(level):\n",
    "            mean_reward = test_model(model, cfg)\n",
    "            print(f\"  Config {j + 1}: {mean_reward:.2f}\")\n",
    "        print()\n",
    "    print()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random level and visualize it\n",
    "random_cnf = random_config(8)\n",
    "print(\"random_cnf:\", random_cnf)\n",
    "\n",
    "print_level_from_config(random_cnf)\n",
    "print_level_from_config(random_cnf)\n",
    "print_level_from_config(random_cnf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/dr_model_8x8.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModels trained on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m grid loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_dr, model_plr, model_accel, model_accel_easy\n\u001b[0;32m---> 17\u001b[0m model_dr, model_plr, model_accel, model_accel_easy \u001b[38;5;241m=\u001b[39m \u001b[43mload_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m rewards \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDR\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLR\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCEL\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCEL-EasyStart\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Test the models on the same exact environment instance\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[30], line 8\u001b[0m, in \u001b[0;36mload_models\u001b[0;34m(grid_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_models\u001b[39m(grid_size):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load the RL models.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     model_dr \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/dr_model_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgrid_size\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgrid_size\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     model_plr \u001b[38;5;241m=\u001b[39m PPO\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/plr_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     model_accel \u001b[38;5;241m=\u001b[39m PPO\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/accel_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:680\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    678\u001b[0m     get_system_info()\n\u001b[0;32m--> 680\u001b[0m data, params, pytorch_variables \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo params found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:403\u001b[0m, in \u001b[0;36mload_from_zip_file\u001b[0;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_zip_file\u001b[39m(\n\u001b[1;32m    377\u001b[0m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath, io\u001b[38;5;241m.\u001b[39mBufferedIOBase],\n\u001b[1;32m    378\u001b[0m     load_data: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     print_system_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/functools.py:909\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    907\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:240\u001b[0m, in \u001b[0;36mopen_path_str\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;129m@open_path\u001b[39m\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m io\u001b[38;5;241m.\u001b[39mBufferedIOBase:\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    that the path exists.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:291\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    285\u001b[0m         path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# if opening was successful uses the open_path() function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:272\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    270\u001b[0m             path, suffix \u001b[38;5;241m=\u001b[39m newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:264\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m open_path(\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, mode, verbose, suffix)\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/pathlib.py:1044\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1043\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1044\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m, mode, buffering, encoding, errors, newline)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/dr_model_8x8.zip'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def load_models(grid_size):\n",
    "    \"\"\"Load the RL models.\"\"\"\n",
    "    model_dr = PPO.load(f\"models/dr_model_{grid_size}x{grid_size}\")\n",
    "    model_plr = PPO.load(f\"models/plr_model_{grid_size}x{grid_size}\")\n",
    "    model_accel = PPO.load(f\"models/accel_model_{grid_size}x{grid_size}\")\n",
    "    model_accel_easy = PPO.load(f\"models/accel_model_easy_{grid_size}x{grid_size}\")\n",
    "    print(f\"Models trained on {grid_size}x{grid_size} grid loaded successfully.\")\n",
    "    \n",
    "    return model_dr, model_plr, model_accel, model_accel_easy\n",
    "\n",
    "\n",
    "model_dr, model_plr, model_accel, model_accel_easy = load_models(8)\n",
    "\n",
    "rewards = {\"DR\": 0, \"PLR\": 0, \"ACCEL\": 0, \"ACCEL-EasyStart\": 0}\n",
    "\n",
    "# Test the models on the same exact environment instance\n",
    "for i in range(20):\n",
    "    config = random_config(8, seed=512 + i)\n",
    "    #print_level_from_config(config)\n",
    "    # Inizialize the environment for each model    \n",
    "\n",
    "    reward = test_model(model_dr, config, gif_path=f\"gifs/level_{i}_dr.gif\")\n",
    "    #print(f\"Reward for level {i} with DR: {reward:.2f}\")\n",
    "    rewards[\"DR\"] += reward\n",
    "    \n",
    "    reward = test_model(model_plr, config, gif_path=f\"gifs/level_{i}_plr.gif\")\n",
    "    #print(f\"Reward for level {i} with PLR: {reward:.2f}\")\n",
    "    rewards[\"PLR\"] += reward\n",
    "    \n",
    "    reward = test_model(model_accel, config, gif_path=f\"gifs/level_{i}_accel.gif\")\n",
    "    #print(f\"Reward for level {i} with ACCEL: {reward:.2f}\")\n",
    "    rewards[\"ACCEL\"] += reward\n",
    "    \n",
    "    reward = test_model(model_accel_easy, config, gif_path=f\"gifs/level_{i}_accel_easy.gif\")\n",
    "    #print(f\"Reward for level {i} with ACCEL-EasyStart: {reward:.2f}\")\n",
    "    rewards[\"ACCEL-EasyStart\"] += reward\n",
    "\n",
    "print(\"Total rewards:\")\n",
    "for model_name, reward in rewards.items():\n",
    "    print(f\"{model_name}: {reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bipedal Walker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://gymnasium.farama.org/environments/box2d/bipedal_walker/\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.utils import obs_as_tensor\n",
    "import random\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "class BipedalWalkerParamWrapper(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    A wrapper around BipedalWalker (or BipedalWalkerHardcore) \n",
    "    that sets custom parameters for terrain generation at reset time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env_id=\"BipedalWalker-v3\", hardcore=False):\n",
    "        super().__init__(gym.make(env_id))\n",
    "        self.hardcore = hardcore\n",
    "\n",
    "        # The environment's internal parameters. \n",
    "        # We will override these at reset to control terrain generation.\n",
    "        self.config = {\n",
    "            \"seed_val\": None,\n",
    "            \"stump_height\": 0.0,\n",
    "            \"stair_height\": 0.0,\n",
    "            \"stair_steps\": 1,\n",
    "            \"roughness\": 0.0,\n",
    "            \"pit_gap\": 0.0,\n",
    "        }\n",
    "\n",
    "        # If we want hardcore version, you can do so with:\n",
    "        if self.hardcore:\n",
    "            self.env = gym.make(\"BipedalWalkerHardcore-v3\")\n",
    "\n",
    "    def set_config(self, config_dict):\n",
    "        \"\"\"Update environment parameters.\"\"\"\n",
    "        for k, v in config_dict.items():\n",
    "            self.config[k] = v\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Modify the environment's terrain parameters right before reset.\n",
    "        This monkey-patches internal Box2D variables, if needed,\n",
    "        or sets seeds to randomize terrain accordingly.\n",
    "        \"\"\"\n",
    "        # 1) Seed:\n",
    "        #if self.config[\"seed_val\"] is not None:\n",
    "        #    self.env.seed(self.config[\"seed_val\"])\n",
    "\n",
    "        # 2) Override terrain parameters in the underlying env\n",
    "        #    (We rely on the environment reading these at reset or having\n",
    "        #     references in the terrain generation code. Depending on \n",
    "        #     your exact BipedalWalker implementation, you might need \n",
    "        #     to modify the source or do partial overrides.)\n",
    "        self.env.unwrapped.stump_height = self.config[\"stump_height\"]\n",
    "        self.env.unwrapped.stair_height = self.config[\"stair_height\"]\n",
    "        self.env.unwrapped.stair_steps = int(self.config[\"stair_steps\"])\n",
    "        self.env.unwrapped.roughness = self.config[\"roughness\"]\n",
    "        self.env.unwrapped.pit_gap = self.config[\"pit_gap\"]\n",
    "\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "    \n",
    "\n",
    "\n",
    "# The min and max values for each terrain parameter.\n",
    "# For simplicity, define them here, but you can store these in a table/dict.\n",
    "PARAM_BOUNDS = {\n",
    "    \"stump_height\":  (0.0, 5.0),\n",
    "    \"stair_height\":  (0.0, 5.0),\n",
    "    \"stair_steps\":   (1,   9),\n",
    "    \"roughness\":     (0.0, 10.0),\n",
    "    \"pit_gap\":       (0.0, 10.0)\n",
    "}\n",
    "\n",
    "def random_config(easy_init=False):\n",
    "    \"\"\"\n",
    "    Sample a random environment config. If easy_init=True,\n",
    "    you might restrict sampling to small values, so the agent\n",
    "    starts with simpler terrain.\n",
    "    \"\"\"\n",
    "    cfg = {}\n",
    "    \n",
    "    # Optionally set a random seed \n",
    "    cfg[\"seed_val\"] = random.randint(0, 1_000_000)\n",
    "\n",
    "    def sample_uniform(low, high):\n",
    "        return random.uniform(low, high)\n",
    "\n",
    "    if easy_init:\n",
    "        # Possibly narrower range for simpler (initial) levels\n",
    "        cfg[\"stump_height\"] = sample_uniform(0.0, 0.4)\n",
    "        cfg[\"stair_height\"] = sample_uniform(0.0, 0.4)\n",
    "        cfg[\"stair_steps\"]  = random.randint(1, 2)\n",
    "        cfg[\"roughness\"]    = sample_uniform(0.0, 0.6)\n",
    "        cfg[\"pit_gap\"]      = sample_uniform(0.0, 0.8)\n",
    "    else:\n",
    "        cfg[\"stump_height\"] = sample_uniform(*PARAM_BOUNDS[\"stump_height\"])\n",
    "        cfg[\"stair_height\"] = sample_uniform(*PARAM_BOUNDS[\"stair_height\"])\n",
    "        cfg[\"stair_steps\"]  = random.randint(*PARAM_BOUNDS[\"stair_steps\"])\n",
    "        cfg[\"roughness\"]    = sample_uniform(*PARAM_BOUNDS[\"roughness\"])\n",
    "        cfg[\"pit_gap\"]      = sample_uniform(*PARAM_BOUNDS[\"pit_gap\"])\n",
    "\n",
    "    return cfg\n",
    "\n",
    "def edit_config(old_cfg):\n",
    "    \"\"\"\n",
    "    Make a small 'mutation' to the old_cfg.\n",
    "    This can be random increments/decrements to each parameter, \n",
    "    or randomly choose one parameter to mutate.\n",
    "    \"\"\"\n",
    "    new_cfg = dict(old_cfg)\n",
    "    param_to_edit = random.choice([\"stump_height\", \"stair_height\", \"stair_steps\", \"roughness\", \"pit_gap\"])\n",
    "    # pick small delta \n",
    "    delta = random.uniform(0.1, 1.0)\n",
    "\n",
    "    # Add or subtract\n",
    "    sign = random.choice([-1, 1])\n",
    "    new_val = new_cfg[param_to_edit] + sign * delta\n",
    "    \n",
    "    # Clip to valid range\n",
    "    low, high = PARAM_BOUNDS[param_to_edit]\n",
    "    new_cfg[param_to_edit] = np.clip(new_val, low, high)\n",
    "\n",
    "    # Possibly update the seed too \n",
    "    new_cfg[\"seed_val\"] = random.randint(0, 1_000_000)\n",
    "    return new_cfg\n",
    "\n",
    "\n",
    "\n",
    "class LevelReplayBuffer:\n",
    "    \"\"\"\n",
    "    Stores (config, score). Score is e.g. a 'regret' approximation.\n",
    "    We keep the highest-score configs up to max_size.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_size=100):\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def add(self, cfg, score):\n",
    "        self.data.append((cfg, score))\n",
    "        # keep only top K by score\n",
    "        self.data.sort(key=lambda x: x[1], reverse=True)\n",
    "        self.data = self.data[:self.max_size]\n",
    "\n",
    "    def sample(self):\n",
    "        if len(self.data) == 0:\n",
    "            return None\n",
    "        # Weighted sample by score or just pick the top \n",
    "        # For simplicity, pick randomly from top half:\n",
    "        half = len(self.data) // 2\n",
    "        idx = np.random.randint(0, max(1, half))\n",
    "        return self.data[idx][0]\n",
    "\n",
    "def estimate_regret(env, model, max_steps=1000, gamma=0.99, lam=0.95):\n",
    "    \"\"\"\n",
    "    Calculate regret using Generalized Advantage Estimation (GAE)\n",
    "    with Stable-Baselines3's PPO model.\n",
    "    \"\"\"\n",
    "    obs = env.reset()[0]\n",
    "    regrets = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    values = []\n",
    "    \n",
    "\n",
    "    for t in range(max_steps):\n",
    "        # Add batch dimension to the observation tensor\n",
    "        obs_tensor = torch.as_tensor(obs).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        # Use the model's policy to get the value and action.\n",
    "        # For actions, model.predict handles single observations well.\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # Compute the value from the policy.\n",
    "        value_t = model.policy.predict_values(obs_tensor).item()\n",
    "        values.append(value_t)\n",
    "        \n",
    "        # Perform the step in the environment\n",
    "        obs, reward, done, truncated, _ = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        dones.append(done)\n",
    "\n",
    "        if done or truncated:\n",
    "            break\n",
    "\n",
    "    # Add value of the terminal state (0 if done/truncated)\n",
    "    if done or truncated:\n",
    "        terminal_value = 0.0\n",
    "    else:\n",
    "        terminal_obs_tensor = torch.as_tensor(obs).float().unsqueeze(0).to(device)\n",
    "        terminal_value = model.policy.predict_values(terminal_obs_tensor).item()\n",
    "    values.append(terminal_value)\n",
    "\n",
    "    # Compute TD-errors and GAE-like regret score\n",
    "    for t in range(len(rewards)):\n",
    "        delta_t = rewards[t] + gamma * values[t + 1] * (1 - dones[t]) - values[t]\n",
    "        discounted_error = (gamma * lam) ** t * delta_t\n",
    "        regrets.append(max(0, discounted_error))\n",
    "\n",
    "    # Return the maximum positive regret score (or 0 if empty)\n",
    "    return max(regrets) if regrets else 0.0\n",
    "\n",
    "def run_accel_bipedal(\n",
    "    total_iterations=50,\n",
    "    steps_per_iteration=10000,\n",
    "    replay_prob=0.8,\n",
    "    regret_threshold=1.0,\n",
    "    max_buf_size=100,\n",
    "    easy_start=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Minimal ACCEL training loop on BipedalWalker.\n",
    "    \"\"\"\n",
    "    # 1) Create the environment wrapper + vectorize\n",
    "    def make_env():\n",
    "        env = BipedalWalkerParamWrapper(env_id=\"BipedalWalkerHardcore-v3\", hardcore=True)\n",
    "        return env\n",
    "    \n",
    "    # (Alternatively, do SubprocVecEnv if you want parallel CPU rollouts.)\n",
    "    vec_env = DummyVecEnv([make_env])\n",
    "\n",
    "    # 2) Initialize PPO\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\", \n",
    "        vec_env, \n",
    "        n_steps=2048,        # must be multiple of vec_env.num_envs\n",
    "        batch_size=64,\n",
    "        learning_rate=3e-4,\n",
    "        gamma=0.99,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # 3) Create LevelReplayBuffer\n",
    "    level_buffer = LevelReplayBuffer(max_size=max_buf_size)\n",
    "\n",
    "    # 4) [Optional] Pre-fill buffer with some easy or random levels\n",
    "    for _ in range(10):  # pre-fill 10 levels\n",
    "        print(\"Pre-filling buffer...\")\n",
    "        cfg = random_config(easy_init=easy_start)\n",
    "        env = make_env()  # fresh environment\n",
    "        env.set_config(cfg)\n",
    "        # Train on it briefly to get a partial updated policy \n",
    "        model.set_env(DummyVecEnv([lambda: env]))\n",
    "        model.learn(total_timesteps=2000)\n",
    "\n",
    "        # Evaluate regret\n",
    "        rew_env = make_env()\n",
    "        rew_env.set_config(cfg)\n",
    "        regret = estimate_regret(rew_env, model)\n",
    "\n",
    "        if regret >= regret_threshold:\n",
    "            level_buffer.add(cfg, regret)\n",
    "        \n",
    "    \n",
    "    print(\"Buffer pre-filled. Starting main loop...\")\n",
    "\n",
    "    # 5) ACCEL main loop\n",
    "    for it in range(total_iterations):\n",
    "        # Decide: replay from buffer or create new\n",
    "        use_replay = (np.random.rand() < replay_prob) and (len(level_buffer.data) > 0)\n",
    "        if use_replay:\n",
    "            cfg = level_buffer.sample()\n",
    "            # Optionally edit the config to keep pushing frontier\n",
    "            cfg = edit_config(cfg)\n",
    "        else:\n",
    "            cfg = random_config(easy_init=False)\n",
    "\n",
    "        # Train on that config\n",
    "        env = make_env()\n",
    "        env.set_config(cfg)\n",
    "        model.set_env(DummyVecEnv([lambda: env]))\n",
    "        model.learn(total_timesteps=steps_per_iteration)\n",
    "\n",
    "        # Now measure regret\n",
    "        rew_env = make_env()\n",
    "        rew_env.set_config(cfg)\n",
    "        regret = estimate_regret(rew_env, model)\n",
    "\n",
    "        if regret >= regret_threshold:\n",
    "            level_buffer.add(cfg, regret)\n",
    "\n",
    "        print(f\"[Iteration {it+1}/{total_iterations}] => Config = {cfg}, Regret = {regret:.3f}, \"\n",
    "              f\"Buffer size = {len(level_buffer.data)}\")\n",
    "\n",
    "    return model, level_buffer\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trained_model, buffer_data = run_accel_bipedal(\n",
    "        total_iterations=250,\n",
    "        steps_per_iteration=1000,\n",
    "        replay_prob=0.8,\n",
    "        regret_threshold=1.0,\n",
    "        max_buf_size=100,\n",
    "        easy_start=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Evaluate final performance on some reference environment\n",
    "    test_env = gym.make(\"BipedalWalkerHardcore-v3\", render_mode='human')\n",
    "    mean_return = 0.0\n",
    "    N = 10\n",
    "    for _ in range(N):\n",
    "        obs = test_env.reset()[0]\n",
    "        done = False\n",
    "        episode_reward = 0.0\n",
    "        while not done:\n",
    "            action, _ = trained_model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, truncated, info = test_env.step(action)\n",
    "            episode_reward += reward\n",
    "            if truncated:\n",
    "                done = True\n",
    "        mean_return += episode_reward\n",
    "    mean_return /= N\n",
    "    print(f\"Avg Return on BipedalWalkerHardcore-v3 over {N} trials: {mean_return}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maze generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomMaze(MiniGridEnv):\n",
    "    \"\"\"\n",
    "    Simple MiniGrid environment that places random wall tiles\n",
    "    according to a config dict, returning only the 'image' observation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config=None, **kwargs):\n",
    "        if config is None:\n",
    "            config = {}\n",
    "        self.config = config\n",
    "\n",
    "        # Extract parameters from config\n",
    "        self.width = config.get(\"width\")\n",
    "        self.height = config.get(\"height\")\n",
    "        self.num_blocks = config.get(\"num_blocks\")\n",
    "        self.custom_seed = config.get(\"seed_val\")\n",
    "        \n",
    "        \n",
    "        # Create a random number generator with the custom seed\n",
    "        self.rng = np.random.default_rng(seed=self.custom_seed)\n",
    "\n",
    "        grid_size = max(self.width, self.height)\n",
    "\n",
    "        mission_space = MissionSpace(mission_func=lambda: \"get to the green goal square\")\n",
    "\n",
    "        super().__init__(\n",
    "            grid_size=grid_size,\n",
    "            max_steps=self.width * self.height * 2, # max_steps is typically 2x the grid size\n",
    "            see_through_walls=False,\n",
    "            agent_view_size=5,                      # Size of the agent's view square\n",
    "            mission_space=mission_space,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # Manually define our observation_space as a single Box (the image).\n",
    "        # By default, MiniGrid's image shape is (view_size, view_size, 3) if using partial obs,\n",
    "        # or (height, width, 3) if using full-grid observation. We'll do full-grid here:\n",
    "        # We'll define (self.height, self.width, 3) as the shape.\n",
    "        # In practice, \"image\" shape can vary if partial observations are used.\n",
    "        self.observation_space = Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(self.agent_view_size, self.agent_view_size, 3),\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "\n",
    "    \n",
    "    def _gen_grid(self, width, height):\n",
    "        \"\"\"\n",
    "        Generate the grid layout for a new episode using the DFS Maze Generation Algorithm.\n",
    "        \"\"\"\n",
    "        # Create an empty grid of the \"true\" width x height from config\n",
    "        self.grid = Grid(self.width, self.height)\n",
    "        # Surround the grid with walls\n",
    "        self.grid.wall_rect(0, 0, self.width, self.height)\n",
    "\n",
    "        # Initialize the maze as walls\n",
    "        maze = [[1 for _ in range(self.width)] for _ in range(self.height)]\n",
    "\n",
    "        # Define directions for DFS\n",
    "        directions = [(0, 2), (0, -2), (2, 0), (-2, 0)]\n",
    "\n",
    "        def is_valid(x, y):\n",
    "            \"\"\"Check if a cell is valid for carving.\"\"\"\n",
    "            return 0 < x < self.height - 1 and 0 < y < self.width - 1 and maze[x][y] == 1\n",
    "\n",
    "        def carve(x, y):\n",
    "            \"\"\"Carve passages in the maze using DFS.\"\"\"\n",
    "            maze[x][y] = 0  # Mark the cell as part of the maze\n",
    "            self.grid.set(x, y, None)  # Clear the wall in the grid\n",
    "            self.rng.shuffle(directions)\n",
    "            for dx, dy in directions:\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if is_valid(nx, ny):\n",
    "                    # Remove the wall between cells\n",
    "                    maze[x + dx // 2][y + dy // 2] = 0\n",
    "                    self.grid.set(x + dx // 2, y + dy // 2, None)\n",
    "                    carve(nx, ny)\n",
    "\n",
    "        # Start carving from the top-left corner\n",
    "        carve(1, 1)\n",
    "\n",
    "        # Place the goal object in a random position not occupied by a wall\n",
    "        while True:\n",
    "            r = self.rng.integers(1, self.height - 1)\n",
    "            c = self.rng.integers(1, self.width - 1)\n",
    "            if self.grid.get(c, r) is None:\n",
    "                self.put_obj(Goal(), c, r)\n",
    "                break\n",
    "\n",
    "        # Place the agent in a random position not occupied by a wall and not on the goal\n",
    "        while True:\n",
    "            r = self.rng.integers(1, self.height - 1)\n",
    "            c = self.rng.integers(1, self.width - 1)\n",
    "            if self.grid.get(c, r) is None:\n",
    "                self.place_agent(top=(c, r), rand_dir=True)\n",
    "                break\n",
    "    \n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Override reset to ensure we only return the 'image' array\n",
    "        instead of a dict with 'image' and 'mission'.\n",
    "        \"\"\"\n",
    "        obs, info = super().reset(**kwargs)\n",
    "        obs = self._convert_obs(obs)\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Same for step: override to convert the dict observation into an image only.\n",
    "        \"\"\"\n",
    "        obs, reward, done, truncated, info = super().step(action)\n",
    "        obs = self._convert_obs(obs)\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "    def _convert_obs(self, original_obs):\n",
    "        \"\"\"\n",
    "        original_obs is typically {'image':..., 'mission':...}.\n",
    "        We'll just return original_obs['image'] to get a Box(low=0,high=255) shape.\n",
    "        \"\"\"\n",
    "        return original_obs[\"image\"]\n",
    "        #return np.transpose(original_obs[\"image\"], (2, 0, 1))\n",
    "\n",
    "\n",
    "\n",
    "def print_maze_from_config(config):\n",
    "    env = MyCustomMaze(config, render_mode='rgb_array')\n",
    "    env.reset()\n",
    "    full_level_image = env.render()  # This should return an RGB image of the full grid\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(full_level_image)\n",
    "    plt.title(\"Maze Configuration: \" + str(config))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Generate a random maze and visualize it\n",
    "random_maze = random_config(6)\n",
    "print_maze_from_config(random_maze)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE, NOT VECORIZED, REDUNDANT CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# ====================================================\n",
    "# 4. Main ACCEL Loop\n",
    "# ====================================================\n",
    "\n",
    "def main_accel_demo(total_iterations, replay_prob, train_steps, level_buffer_size,\n",
    "                    initial_fill_size, grid_size):\n",
    "    \n",
    "    \n",
    "    # Create a level buffer to store generated levels and their scores\n",
    "    level_buffer = LevelBuffer(max_size=level_buffer_size)\n",
    "    iteration_regrets = []\n",
    "        \n",
    "    #Create a dummy environment to initialize the model\n",
    "    dummy_env = MyCustomGrid(random_config(grid_size))\n",
    "    vectorized_env = create_vectorized_env(dummy_env, n_envs=4)\n",
    "\n",
    "    # Initialize student model with PPO\n",
    "    print(\"Initializing student model PPO...\")\n",
    "    student_model = initialize_ppo(dummy_env)\n",
    "\n",
    "    skipped = 0\n",
    "\n",
    "    # Populate buffer with initial levels\n",
    "    print(f\"Populating buffer with {initial_fill_size} initial levels with regret != 0...\")\n",
    "    for _ in range(initial_fill_size + skipped):\n",
    "        cfg = random_config(grid_size)\n",
    "        regret = calculate_regret_gae(MyCustomGrid(cfg), student_model, max_steps=1000, gamma=0.99, lam=0.95)\n",
    "        \n",
    "        # Skip levels with 0 regret\n",
    "        if regret == 0:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        level_buffer.add(cfg, regret)\n",
    "        \n",
    "    \n",
    "    print(\"\\nDone. Number of skipped levels with zero regret:\", skipped)\n",
    "    \n",
    "    skipped = 0\n",
    "    iteration = 0\n",
    "    # Main ACCEL loop\n",
    "    print(\"\\nMain ACCEL loop...\")\n",
    "    while iteration < total_iterations + skipped:\n",
    "        print(f\"\\n=== ITERATION {iteration + 1}/{total_iterations} SKIPPED {skipped} ===\")\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Decide whether to use replay or generate a new level\n",
    "        use_replay = np.random.rand() < replay_prob\n",
    "        \n",
    "        # Generates new random levels if you don't use replay\n",
    "        if not use_replay or len(level_buffer.data) == 0:\n",
    "            cfg = random_config(grid_size)\n",
    "            regret = calculate_regret_gae(MyCustomGrid(cfg), student_model, max_steps=100, gamma=0.99, lam=0.95)\n",
    "            \n",
    "            if regret == 0:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            \n",
    "            level_buffer.add(cfg, regret)\n",
    "            print(f\"  Sampled new config, regret={regret:.3f}\")\n",
    "        else:\n",
    "            # Replays an existing layer, edits it, and evaluates the new layer\n",
    "            old_cfg = level_buffer.sample_config()\n",
    "            env = MyCustomGrid(old_cfg)\n",
    "            \n",
    "            student_model.set_env(env)\n",
    "            student_model.learn(total_timesteps=train_steps)\n",
    "\n",
    "            new_cfg = edit_config(old_cfg)\n",
    "            regret = calculate_regret_gae(MyCustomGrid(new_cfg), student_model, max_steps=100, gamma=0.99, lam=0.95)\n",
    "            \n",
    "            if regret == 0:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            \n",
    "            level_buffer.add(new_cfg, regret)\n",
    "            print(f\"  Replayed + mutated config, regret={regret:.3f}\")\n",
    "        \n",
    "        iteration_regrets.append(regret)\n",
    "    \n",
    "    print(\"\\nDone. Number of skipped levels with zero regret:\", skipped)\n",
    "\n",
    "    # Visualize progress of the regret over iterations.\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(iteration_regrets, marker='o')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Regret\")\n",
    "    plt.title(\"Regret Progress during ACCEL Training\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    config = {\n",
    "        \"grid_size\": 8,\n",
    "        \n",
    "        \"total_iterations\": 64,\n",
    "        \"train_steps\": 1024,\n",
    "\n",
    "        \"replay_prob\": 0.7,           # Probability of replaying a level and editing it vs. generating a new one\n",
    "        \"level_buffer_size\": 128,     # Maximum number of levels to store in the buffer\n",
    "        \"initial_fill_size\": 64,      # Number of levels to pre-fill the buffer with\n",
    "        \"regret_threshold\": 0.0,      # Minimum regret threshold to consider a level for the buffer\n",
    "        \n",
    "        \"n_envs\": 8,                  # Number of parallel environments to use for training\n",
    "        \n",
    "        \"edit_levels\": True,          # Whether to edit levels during training i.e. ACCEL or PLR\n",
    "        \"easy_start\": True            # Whether to fill the buffer with easy levels first i.e. minimum number of blocks\n",
    "    }\n",
    "    \n",
    "    print(\"Running ACCEL with config:\")\n",
    "    print(config, \"\\n\")\n",
    "    \n",
    "    main_accel(**config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_regret_gae_parallel(env_config, model, max_steps=1000, gamma=0.99, lam=0.95, n_envs=4):\n",
    "    '''\n",
    "    Roll out n_envs copies of MyCustomGrid(env_config) in parallel,\n",
    "    compute GAE-based 'regret' for each environment, and return the max.\n",
    "    '''\n",
    "\n",
    "    # Create vectorized env with n_envs copies\n",
    "    vec_env = create_vectorized_env(env_config, n_envs=n_envs)\n",
    "    obs_array = vec_env.reset()  # shape: (n_envs, height, width, 3)\n",
    "\n",
    "    # For each environment, we will store transitions to later compute GAE\n",
    "    # We'll keep them in lists, one per environment.\n",
    "    # Alternatively, we can store them in big arrays (n_envs, max_steps), etc.\n",
    "    rewards_list = [[] for _ in range(n_envs)]\n",
    "    values_list = [[] for _ in range(n_envs)]\n",
    "    dones_list = [[] for _ in range(n_envs)]\n",
    "\n",
    "    for t in range(max_steps):\n",
    "        # Model’s predict can handle multiple obs in a single forward pass\n",
    "        actions, _ = model.predict(obs_array, deterministic=True)\n",
    "        \n",
    "        # Also compute the values in one batch\n",
    "        # Convert obs_array to torch tensor\n",
    "        obs_tensor = torch.as_tensor(np.transpose(obs_array, (0, 3, 1, 2))).float().to(device)\n",
    "        with torch.no_grad():\n",
    "            # shape: (n_envs, 1)\n",
    "            value_t = model.policy.predict_values(obs_tensor).cpu().numpy().flatten()\n",
    "\n",
    "        # Step all envs in parallel\n",
    "        next_obs_array, rewards, dones, truncs = vec_env.step(actions)\n",
    "\n",
    "        # Store the results\n",
    "        for i in range(n_envs):\n",
    "            rewards_list[i].append(rewards[i])\n",
    "            values_list[i].append(value_t[i])\n",
    "            dones_list[i].append(bool(dones[i]) or bool(truncs[i]))\n",
    "\n",
    "        obs_array = next_obs_array\n",
    "\n",
    "        # If all envs are done or truncated, we can break early\n",
    "        if all(dones) or all(truncs):\n",
    "            break\n",
    "\n",
    "    # We also need the terminal value for each env\n",
    "    # (0 if done, otherwise model's value at final obs)\n",
    "    obs_tensor = torch.as_tensor(np.transpose(obs_array, (0, 3, 1, 2))).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        final_values = model.policy.predict_values(obs_tensor).cpu().numpy().flatten()\n",
    "\n",
    "    # Now, compute GAE-based \"regret\" for each of the n_envs\n",
    "    regrets = []\n",
    "    for i in range(n_envs):\n",
    "        # If the env ended with done or truncated, terminal value = 0\n",
    "        if dones_list[i][-1]:\n",
    "            values_list[i].append(0.0)\n",
    "        else:\n",
    "            values_list[i].append(final_values[i])\n",
    "\n",
    "        # Compute delta_t and approximate GAE-like metric\n",
    "        env_rewards = rewards_list[i]\n",
    "        env_values = values_list[i]\n",
    "        env_dones = dones_list[i]\n",
    "\n",
    "        env_regrets = []\n",
    "        for t in range(len(env_rewards)):\n",
    "            delta_t = env_rewards[t] + gamma * env_values[t + 1] * (1 - env_dones[t]) - env_values[t]\n",
    "            # accumulate discounted error\n",
    "            discounted_error = (gamma * lam) ** t * delta_t\n",
    "            env_regrets.append(max(0, discounted_error))\n",
    "\n",
    "        # The environment's \"regret\" is the max of its positive GAE deltas\n",
    "        regrets.append(max(env_regrets) if env_regrets else 0.0)\n",
    "\n",
    "    # Return the maximum regret across the parallel envs\n",
    "    return max(regrets) if regrets else 0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    def _gen_grid(self, width, height):\n",
    "        '''\n",
    "        Generate the grid layout for a new episode.\n",
    "        We use self.width and self.height from config, even though the underlying\n",
    "        MiniGrid environment might use grid_size for some of its operations.\n",
    "        '''    \n",
    "        \n",
    "        # Create an empty grid of the \"true\" width x height from config\n",
    "        self.grid = Grid(self.width, self.height)\n",
    "        # Surround the grid with walls\n",
    "        self.grid.wall_rect(0, 0, self.width, self.height)\n",
    "        \n",
    "        # Place random walls inside using the custom seed. Only place a wall if the cell is empty.\n",
    "        for _ in range(self.num_blocks):\n",
    "            r = self.rng.integers(1, self.height - 1)\n",
    "            c = self.rng.integers(1, self.width - 1)\n",
    "            if self.grid.get(c, r) is None: #and (c, r) != self.config[\"start_pos\"] and (c, r) != self.config[\"goal_pos\"]:\n",
    "                self.put_obj(Wall(), c, r)\n",
    "        \n",
    "        # Place the goal object in a random position not occupied by any wall\n",
    "        \"\"\"if self.config[\"goal_pos\"] is None:\"\"\"\n",
    "        while True:\n",
    "            r = self.rng.integers(1, self.height - 1)\n",
    "            c = self.rng.integers(1, self.width - 1)\n",
    "            if self.grid.get(c, r) is None: # and (c, r) != self.config[\"start_pos\"]:\n",
    "                self.put_obj(Goal(), c, r)\n",
    "                self.config[\"goal_pos\"] = (c, r)\n",
    "                break\n",
    "        \"\"\"elif self.config[\"goal_pos\"] is not None:\n",
    "            c, r = self.config[\"goal_pos\"]\n",
    "            self.put_obj(Goal(), c, r)\"\"\"\n",
    "\n",
    "        # Place the agent in a random position not occupied by any wall and not on the goal\n",
    "        \n",
    "        \"\"\"if self.config[\"start_pos\"] is None:\"\"\"\n",
    "        while True:\n",
    "            r = self.rng.integers(1, self.height - 1)\n",
    "            c = self.rng.integers(1, self.width - 1)\n",
    "            if self.grid.get(c, r) is None: # and (c, r) != self.config[\"goal_pos\"]:\n",
    "                self.place_agent(top=(c, r), rand_dir=True)\n",
    "                self.config[\"start_pos\"] = (c, r)\n",
    "                break  \n",
    "        \"\"\"elif self.config[\"start_pos\"] is not None:\n",
    "            c, r = self.config[\"start_pos\"]\n",
    "            self.place_agent(top=(c, r), rand_dir=True)\"\"\"'''\n",
    "            \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
