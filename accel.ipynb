{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANGER: ACCEL does not use a teacher, but a single student that learns from levels selected by a curator, in this impmenetation the curator is a sampler that gives te studemt with a probabilistic manner, the highest regret-based score level, but instaed of discarding the levels during training, it makes small edits to the most diffucult ones, gibing the change to rely on already good but hard leves without the need of a teacher.\n",
    "# TODO: the start_pos and goal_pos of edited levels are uncorrectly marked, if I mutate the level no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "from gymnasium.spaces import Box\n",
    "\n",
    "from minigrid.core.mission import MissionSpace\n",
    "from minigrid.core.world_object import Goal, Wall\n",
    "from minigrid.minigrid_env import MiniGridEnv, Grid\n",
    "\n",
    "from minigrid.wrappers import ImgObsWrapper\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ====================================================\n",
    "# 1. Custom MiniGrid Environment that returns only the image\n",
    "#    for SB3's PPO (which expects a Box space).\n",
    "# ====================================================\n",
    "class MyCustomGrid(MiniGridEnv):\n",
    "    \"\"\"\n",
    "    Simple MiniGrid environment that places random wall tiles\n",
    "    according to a config dict, returning only the 'image' observation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config=None, **kwargs):\n",
    "        if config is None:\n",
    "            config = {}\n",
    "        self.config = config\n",
    "\n",
    "        # Extract parameters from config\n",
    "        self.width = config.get(\"width\")\n",
    "        self.height = config.get(\"height\")\n",
    "        self.num_blocks = config.get(\"num_blocks\")\n",
    "        self.custom_seed = config.get(\"seed_val\")\n",
    "        \n",
    "        \n",
    "        # Create a random number generator with the custom seed\n",
    "        self.rng = np.random.default_rng(seed=self.custom_seed)\n",
    "\n",
    "        grid_size = max(self.width, self.height)\n",
    "\n",
    "        mission_space = MissionSpace(mission_func=lambda: \"get to the green goal square\")\n",
    "\n",
    "        super().__init__(\n",
    "            grid_size=grid_size,\n",
    "            max_steps=self.width * self.height * 2, # max_steps is typically 2x the grid size\n",
    "            see_through_walls=False,\n",
    "            agent_view_size=5,                      # Size of the agent's view square\n",
    "            mission_space=mission_space,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # Manually define our observation_space as a single Box (the image).\n",
    "        # By default, MiniGrid's image shape is (view_size, view_size, 3) if using partial obs,\n",
    "        # or (height, width, 3) if using full-grid observation. We'll do full-grid here:\n",
    "        # We'll define (self.height, self.width, 3) as the shape.\n",
    "        # In practice, \"image\" shape can vary if partial observations are used.\n",
    "        self.observation_space = Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(self.agent_view_size, self.agent_view_size, 3),\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "\n",
    "    def _gen_grid(self, width, height):\n",
    "        \"\"\"\n",
    "        Generate the grid layout for a new episode.\n",
    "        We use self.width and self.height from config, even though the underlying\n",
    "        MiniGrid environment might use grid_size for some of its operations.\n",
    "        \"\"\"    \n",
    "        \n",
    "        # Create an empty grid of the \"true\" width x height from config\n",
    "        self.grid = Grid(self.width, self.height)\n",
    "        # Surround the grid with walls\n",
    "        self.grid.wall_rect(0, 0, self.width, self.height)\n",
    "        \n",
    "        # Place random walls inside using the custom seed. Only place a wall if the cell is empty.\n",
    "        for _ in range(self.num_blocks):\n",
    "            r = self.rng.integers(1, self.height - 1)\n",
    "            c = self.rng.integers(1, self.width - 1)\n",
    "            if self.grid.get(c, r) is None: #and (c, r) != self.config[\"start_pos\"] and (c, r) != self.config[\"goal_pos\"]:\n",
    "                self.put_obj(Wall(), c, r)\n",
    "        \n",
    "        # Place the goal object in a random position not occupied by any wall\n",
    "        \"\"\"if self.config[\"goal_pos\"] is None:\"\"\"\n",
    "        while True:\n",
    "            r = self.rng.integers(1, self.height - 1)\n",
    "            c = self.rng.integers(1, self.width - 1)\n",
    "            if self.grid.get(c, r) is None: # and (c, r) != self.config[\"start_pos\"]:\n",
    "                self.put_obj(Goal(), c, r)\n",
    "                self.config[\"goal_pos\"] = (c, r)\n",
    "                break\n",
    "        \"\"\"elif self.config[\"goal_pos\"] is not None:\n",
    "            c, r = self.config[\"goal_pos\"]\n",
    "            self.put_obj(Goal(), c, r)\"\"\"\n",
    "\n",
    "        # Place the agent in a random position not occupied by any wall and not on the goal\n",
    "        \n",
    "        \"\"\"if self.config[\"start_pos\"] is None:\"\"\"\n",
    "        while True:\n",
    "            r = self.rng.integers(1, self.height - 1)\n",
    "            c = self.rng.integers(1, self.width - 1)\n",
    "            if self.grid.get(c, r) is None: # and (c, r) != self.config[\"goal_pos\"]:\n",
    "                self.place_agent(top=(c, r), rand_dir=True)\n",
    "                self.config[\"start_pos\"] = (c, r)\n",
    "                break  \n",
    "        \"\"\"elif self.config[\"start_pos\"] is not None:\n",
    "            c, r = self.config[\"start_pos\"]\n",
    "            self.place_agent(top=(c, r), rand_dir=True)\"\"\"\n",
    "     \n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Override reset to ensure we only return the 'image' array\n",
    "        instead of a dict with 'image' and 'mission'.\n",
    "        \"\"\"\n",
    "        obs, info = super().reset(**kwargs)\n",
    "        obs = self._convert_obs(obs)\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Same for step: override to convert the dict observation into an image only.\n",
    "        \"\"\"\n",
    "        obs, reward, done, truncated, info = super().step(action)\n",
    "        obs = self._convert_obs(obs)\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "    def _convert_obs(self, original_obs):\n",
    "        \"\"\"\n",
    "        original_obs is typically {'image':..., 'mission':...}.\n",
    "        We'll just return original_obs['image'] to get a Box(low=0,high=255) shape.\n",
    "        \"\"\"\n",
    "        return original_obs[\"image\"]\n",
    "        #return np.transpose(original_obs[\"image\"], (2, 0, 1))\n",
    "\n",
    "\n",
    "\n",
    "def random_config(grid_size, num_blocks=None):\n",
    "    max_blocks = int(((grid_size - 1) * (grid_size - 1)) / 2)\n",
    "    \n",
    "    if num_blocks is None:\n",
    "        num_blocks = np.random.randint(1, max_blocks)\n",
    "    else:\n",
    "        num_blocks = min(num_blocks, max_blocks)\n",
    "    \n",
    "    return {\n",
    "        \"width\": grid_size,\n",
    "        \"height\": grid_size,\n",
    "        \"num_blocks\": num_blocks,\n",
    "        \"start_pos\": None,\n",
    "        \"goal_pos\": None,\n",
    "        \"edited\": False,\n",
    "        \"seed_val\": np.random.randint(0, 999999),\n",
    "    }\n",
    "    \n",
    "# Modify an existing configuration, adding randomness.\n",
    "def edit_config(old_config):\n",
    "    max_blocks = int(((old_config[\"width\"] - 1) * (old_config[\"height\"] - 1)) / 2)\n",
    "    \n",
    "    new_config = dict(old_config)\n",
    "    \n",
    "    # Randomly change the number of blocks\n",
    "    new_number_blocks = old_config[\"num_blocks\"] + np.random.choice([1])\n",
    "    \n",
    "    # Ensure the number of blocks is within bounds\n",
    "    new_config[\"num_blocks\"] = max(1, min(new_number_blocks, max_blocks))    \n",
    "    \n",
    "    # Mark the config as edited\n",
    "    new_config[\"edited\"] = True\n",
    "    \n",
    "    return new_config\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 2. Simple “level buffer” \n",
    "# ====================================================\n",
    "# class to memorize generated levels and score\n",
    "class LevelBuffer: \n",
    "    def __init__(self, max_size=50):\n",
    "        self.max_size = max_size\n",
    "        self.data = []  # will store (config_dict, score)\n",
    "\n",
    "    def add(self, config, score):\n",
    "        self.data.append((config, score))\n",
    "        if len(self.data) > self.max_size:\n",
    "            self.data.sort(key=lambda x: x[1], reverse=True)\n",
    "            self.data = self.data[: self.max_size]\n",
    "            #it memorize only the highest score for each level\n",
    "\n",
    "    def sample_config(self): \n",
    "        # Samples a level from the buffer, weighting the probabilities \n",
    "        # based on the scores.\n",
    "        if len(self.data) == 0:\n",
    "            return None\n",
    "        scores = [item[1] for item in self.data]\n",
    "        total = sum(scores)\n",
    "        if total <= 1e-9:\n",
    "            # fallback to uniform\n",
    "            idx = np.random.randint(len(self.data))\n",
    "            return self.data[idx][0]\n",
    "        probs = [s / total for s in scores]\n",
    "        idx = np.random.choice(len(self.data), p=probs)\n",
    "        return self.data[idx][0]\n",
    "\n",
    "# ====================================================\n",
    "# 3. Utility Functions\n",
    "# ====================================================\n",
    "\n",
    "# Calculate regret using Generalized Advantage Estimation (GAE) with Stable-Baselines3's PPO model.\n",
    "# PLR approximates regret using a score function such as the positive value loss.\n",
    "def calculate_regret_gae(env, model, max_steps, gamma, lam):\n",
    "    \"\"\"\n",
    "    Calculate regret using Generalized Advantage Estimation (GAE)\n",
    "    with Stable-Baselines3's PPO model.\n",
    "    \"\"\"\n",
    "    obs, _ = env.reset()\n",
    "    regrets = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    values = []\n",
    "\n",
    "    for t in range(max_steps):\n",
    "        # Add batch dimension to the observation tensor\n",
    "        obs_tensor = torch.as_tensor(obs).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        # Use the model's policy to get the value and action.\n",
    "        # For actions, model.predict handles single observations well.\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # Compute the value from the policy.\n",
    "        value_t = model.policy.predict_values(obs_tensor).item()\n",
    "        values.append(value_t)\n",
    "        \n",
    "        # Perform the step in the environment\n",
    "        obs, reward, done, truncated, _ = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        dones.append(done)\n",
    "\n",
    "        if done or truncated:\n",
    "            break\n",
    "\n",
    "    # Add value of the terminal state (0 if done/truncated)\n",
    "    if done or truncated:\n",
    "        terminal_value = 0.0\n",
    "    else:\n",
    "        terminal_obs_tensor = torch.as_tensor(obs).float().unsqueeze(0).to(device)\n",
    "        terminal_value = model.policy.predict_values(terminal_obs_tensor).item()\n",
    "    values.append(terminal_value)\n",
    "\n",
    "    # Compute TD-errors and GAE-like regret score\n",
    "    for t in range(len(rewards)):\n",
    "        delta_t = rewards[t] + gamma * values[t + 1] * (1 - dones[t]) - values[t]\n",
    "        discounted_error = (gamma * lam) ** t * delta_t\n",
    "        regrets.append(max(0, discounted_error))\n",
    "\n",
    "    # Return the maximum positive regret score (or 0 if empty)\n",
    "    return max(regrets) if regrets else 0.0\n",
    "\n",
    "\n",
    "\n",
    "def calculate_regret_gae_parallel(env_config, model, max_steps=1000, gamma=0.99, lam=0.95, n_envs=4):\n",
    "    \"\"\"\n",
    "    Roll out n_envs copies of MyCustomGrid(env_config) in parallel,\n",
    "    compute GAE-based 'regret' for each environment, and return the max.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create vectorized env with n_envs copies\n",
    "    vec_env = create_vectorized_env(env_config, n_envs=n_envs)\n",
    "    obs_array = vec_env.reset()  # shape: (n_envs, height, width, 3)\n",
    "\n",
    "    # For each environment, we will store transitions to later compute GAE\n",
    "    # We'll keep them in lists, one per environment.\n",
    "    # Alternatively, we can store them in big arrays (n_envs, max_steps), etc.\n",
    "    rewards_list = [[] for _ in range(n_envs)]\n",
    "    values_list = [[] for _ in range(n_envs)]\n",
    "    dones_list = [[] for _ in range(n_envs)]\n",
    "\n",
    "    for t in range(max_steps):\n",
    "        # Model’s predict can handle multiple obs in a single forward pass\n",
    "        actions, _ = model.predict(obs_array, deterministic=True)\n",
    "        \n",
    "        # Also compute the values in one batch\n",
    "        # Convert obs_array to torch tensor\n",
    "        obs_tensor = torch.as_tensor(np.transpose(obs_array, (0, 3, 1, 2))).float().to(device)\n",
    "        with torch.no_grad():\n",
    "            # shape: (n_envs, 1)\n",
    "            value_t = model.policy.predict_values(obs_tensor).cpu().numpy().flatten()\n",
    "\n",
    "        # Step all envs in parallel\n",
    "        next_obs_array, rewards, dones, truncs = vec_env.step(actions)\n",
    "\n",
    "        # Store the results\n",
    "        for i in range(n_envs):\n",
    "            rewards_list[i].append(rewards[i])\n",
    "            values_list[i].append(value_t[i])\n",
    "            dones_list[i].append(bool(dones[i]) or bool(truncs[i]))\n",
    "\n",
    "        obs_array = next_obs_array\n",
    "\n",
    "        # If all envs are done or truncated, we can break early\n",
    "        if all(dones) or all(truncs):\n",
    "            break\n",
    "\n",
    "    # We also need the terminal value for each env\n",
    "    # (0 if done, otherwise model's value at final obs)\n",
    "    obs_tensor = torch.as_tensor(np.transpose(obs_array, (0, 3, 1, 2))).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        final_values = model.policy.predict_values(obs_tensor).cpu().numpy().flatten()\n",
    "\n",
    "    # Now, compute GAE-based \"regret\" for each of the n_envs\n",
    "    regrets = []\n",
    "    for i in range(n_envs):\n",
    "        # If the env ended with done or truncated, terminal value = 0\n",
    "        if dones_list[i][-1]:\n",
    "            values_list[i].append(0.0)\n",
    "        else:\n",
    "            values_list[i].append(final_values[i])\n",
    "\n",
    "        # Compute delta_t and approximate GAE-like metric\n",
    "        env_rewards = rewards_list[i]\n",
    "        env_values = values_list[i]\n",
    "        env_dones = dones_list[i]\n",
    "\n",
    "        env_regrets = []\n",
    "        for t in range(len(env_rewards)):\n",
    "            delta_t = env_rewards[t] + gamma * env_values[t + 1] * (1 - env_dones[t]) - env_values[t]\n",
    "            # accumulate discounted error\n",
    "            discounted_error = (gamma * lam) ** t * delta_t\n",
    "            env_regrets.append(max(0, discounted_error))\n",
    "\n",
    "        # The environment's \"regret\" is the max of its positive GAE deltas\n",
    "        regrets.append(max(env_regrets) if env_regrets else 0.0)\n",
    "\n",
    "    # Return the maximum regret across the parallel envs\n",
    "    return max(regrets) if regrets else 0.0\n",
    "\n",
    "\n",
    "def initialize_ppo(env, learning_rate=1e-4):\n",
    "    return PPO(\n",
    "        \"MlpPolicy\",                   # Multi-layer perceptron policy\n",
    "        #\"CnnPolicy\",                    # Convolutional neural network policy (For GPU)\n",
    "        env,                            # environment to learn from\n",
    "        verbose=0,                      # Display training output\n",
    "        n_steps=32,                    # Number of steps to run for each environment per update\n",
    "        batch_size=32,                  # Minibatch size for each gradient update\n",
    "        learning_rate=learning_rate,\n",
    "        device=device                   # Use GPU if available\n",
    "        \n",
    "    )\n",
    "\n",
    "def print_level_from_config(config):\n",
    "    env = MyCustomGrid(config, render_mode='rgb_array')\n",
    "    env.reset()\n",
    "    full_level_image = env.render()  # This should return an RGB image of the full grid\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(full_level_image)\n",
    "    plt.title(\"Level Configuration: \" + str(config))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "# Use vectorized environment\n",
    "def create_vectorized_env(config, n_envs=4):\n",
    "    \"\"\"\n",
    "    Create a vectorized environment with n parallel environments.\n",
    "    \"\"\"\n",
    "    env_fns = [lambda: MyCustomGrid(config) for _ in range(n_envs)]\n",
    "    return make_vec_env(lambda: MyCustomGrid(config), n_envs=n_envs, vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "\n",
    "\n",
    "def main_accel(total_iterations, replay_prob, train_steps, level_buffer_size,\n",
    "                    initial_fill_size, grid_size, n_envs, edit_levels, regret_threshold,\n",
    "                    easy_start, parallel_regret):\n",
    "    # Create a level buffer\n",
    "    level_buffer = LevelBuffer(max_size=level_buffer_size)\n",
    "    iteration_regrets = []\n",
    "\n",
    "    # Use a random config to create a vectorized environment\n",
    "    dummy_config = random_config(grid_size)\n",
    "    vectorized_env = create_vectorized_env(dummy_config, n_envs=n_envs)\n",
    "\n",
    "    # Initialize PPO with vectorized environment\n",
    "    print(\"Initializing student model PPO...\")\n",
    "    student_model = initialize_ppo(vectorized_env)\n",
    "\n",
    "    # Populate buffer with initial levels\n",
    "    print(f\"Populating buffer with {initial_fill_size} initial levels with regret > {regret_threshold}...\")\n",
    "    while len(level_buffer.data) < initial_fill_size:\n",
    "        \n",
    "        if easy_start:\n",
    "            cfg = random_config(grid_size, num_blocks=2)\n",
    "        else:\n",
    "            cfg = random_config(grid_size)\n",
    "        \n",
    "        if parallel_regret:\n",
    "            regret = calculate_regret_gae_parallel(cfg, student_model, max_steps=1000, gamma=0.99, lam=0.95, n_envs=n_envs)\n",
    "        else:\n",
    "            regret = calculate_regret_gae(MyCustomGrid(cfg), student_model, max_steps=1000, gamma=0.99, lam=0.95)\n",
    "\n",
    "        # Skip levels with low regret\n",
    "        if regret < regret_threshold:\n",
    "            continue\n",
    "\n",
    "        level_buffer.add(cfg, regret)\n",
    "\n",
    "    # Main ACCEL loop\n",
    "    iteration, skipped = 0, 0\n",
    "    print(\"\\nMain training loop...\")\n",
    "    while iteration < total_iterations + skipped:\n",
    "        print(f\"\\n=== ITERATION {iteration + 1}/{total_iterations + skipped} SKIPPED: {skipped} ===\")\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Decide whether to replay or generate a new level\n",
    "        use_replay = np.random.rand() < replay_prob\n",
    "\n",
    "        if not use_replay or len(level_buffer.data) == 0:\n",
    "            # Create a new random level\n",
    "            cfg = random_config(grid_size)\n",
    "            print(\"Generated new random level:\", cfg)\n",
    "        else:\n",
    "            # Sample a level from the buffer\n",
    "            cfg = level_buffer.sample_config()\n",
    "            print(\"Sampled level from buffer:\", cfg)\n",
    "            \n",
    "        # Update the vectorized environment with the selected config and train the model\n",
    "        vectorized_env = create_vectorized_env(cfg, n_envs=n_envs)\n",
    "        student_model.set_env(vectorized_env)\n",
    "        student_model.learn(total_timesteps=train_steps)\n",
    "\n",
    "        if use_replay and edit_levels:\n",
    "            # Edit the level and calculate regret\n",
    "            cfg = edit_config(cfg)\n",
    "            print(\"Edited level to:\", cfg)\n",
    "        \n",
    "        if parallel_regret:\n",
    "            regret = calculate_regret_gae_parallel(cfg, student_model, max_steps=2000, gamma=0.99, lam=0.95, n_envs=n_envs)\n",
    "        else:\n",
    "            regret = calculate_regret_gae(MyCustomGrid(cfg), student_model, max_steps=1000, gamma=0.99, lam=0.95)\n",
    "        \n",
    "        if regret <= regret_threshold:\n",
    "            print(f\"Regret for current level is {regret:.5f} <= threshold {regret_threshold}. Skipping...\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        print(f\"Regret for current level: {regret}\")\n",
    "        level_buffer.add(cfg, regret)\n",
    "        iteration_regrets.append(regret)\n",
    "        \n",
    "    \n",
    "    # Plot and display the progress\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(iteration_regrets, marker='o')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Regret\")\n",
    "    plt.title(\"Regret Progress during ACCEL Training\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nDone. Final buffer size:\", len(level_buffer.data))\n",
    "    print(\"Top-5 hardest levels (config, regret):\")\n",
    "    level_buffer.data.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i, (cfg, sc) in enumerate(level_buffer.data[:5]):\n",
    "        print(f\"{i + 1}. regret={sc:.5f}, config={cfg}\")\n",
    "        #print_level_from_config(cfg)\n",
    "        \n",
    "    print(\"Top-5 easiest levels (config, regret):\")\n",
    "    level_buffer.data.sort(key=lambda x: x[1])\n",
    "    for i, (cfg, sc) in enumerate(level_buffer.data[:5]):\n",
    "        print(f\"{i + 1}. regret={sc:.5f}, config={cfg}\")\n",
    "        #print_level_from_config(cfg)\n",
    "    \n",
    "    return student_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PLR with config: {'grid_size': 11, 'total_iterations': 500, 'train_steps': 500, 'replay_prob': 0.7, 'level_buffer_size': 128, 'initial_fill_size': 64, 'regret_threshold': 0.0, 'n_envs': 4, 'edit_levels': False, 'easy_start': False, 'parallel_regret': False}\n",
      "Initializing student model PPO...\n",
      "Populating buffer with 64 initial levels with regret > 0.0...\n",
      "\n",
      "Main training loop...\n",
      "\n",
      "=== ITERATION 1/500 SKIPPED: 0 ===\n",
      "Sampled level from buffer: {'width': 11, 'height': 11, 'num_blocks': 38, 'start_pos': (2, 9), 'goal_pos': (8, 1), 'edited': False, 'seed_val': 383136}\n",
      "Regret for current level is 0.00000 <= threshold 0.0. Skipping...\n",
      "\n",
      "=== ITERATION 2/501 SKIPPED: 1 ===\n",
      "Sampled level from buffer: {'width': 11, 'height': 11, 'num_blocks': 31, 'start_pos': (4, 4), 'goal_pos': (2, 8), 'edited': False, 'seed_val': 627969}\n",
      "Regret for current level: 0.006365892520311456\n",
      "\n",
      "=== ITERATION 3/501 SKIPPED: 1 ===\n",
      "Sampled level from buffer: {'width': 11, 'height': 11, 'num_blocks': 38, 'start_pos': (2, 9), 'goal_pos': (8, 1), 'edited': False, 'seed_val': 383136}\n",
      "Regret for current level: 0.02135152288680858\n",
      "\n",
      "=== ITERATION 4/501 SKIPPED: 1 ===\n",
      "Sampled level from buffer: {'width': 11, 'height': 11, 'num_blocks': 38, 'start_pos': (2, 9), 'goal_pos': (8, 1), 'edited': False, 'seed_val': 383136}\n",
      "Regret for current level: 4.425616934895533e-05\n",
      "\n",
      "=== ITERATION 5/501 SKIPPED: 1 ===\n",
      "Sampled level from buffer: {'width': 11, 'height': 11, 'num_blocks': 41, 'start_pos': (2, 6), 'goal_pos': (1, 5), 'edited': False, 'seed_val': 490095}\n",
      "Regret for current level: 9.441259317100048e-05\n",
      "\n",
      "=== ITERATION 6/501 SKIPPED: 1 ===\n",
      "Sampled level from buffer: {'width': 11, 'height': 11, 'num_blocks': 38, 'start_pos': (2, 9), 'goal_pos': (8, 1), 'edited': False, 'seed_val': 383136}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "        \"grid_size\": 11,\n",
    "        \n",
    "        \"total_iterations\": 500,\n",
    "        \"train_steps\": 500,\n",
    "\n",
    "        \"replay_prob\": 0.7,           # Probability of replaying a level and editing it vs. generating a new one\n",
    "        \"level_buffer_size\": 128,     # Maximum number of levels to store in the buffer\n",
    "        \"initial_fill_size\": 64,      # Number of levels to pre-fill the buffer with\n",
    "        \"regret_threshold\": 0.0,      # Minimum regret threshold to consider a level for the buffer\n",
    "        \n",
    "        \"n_envs\": 4,                  # Number of parallel environments to use for training\n",
    "        \n",
    "        \"edit_levels\": True,          # Whether to edit levels during training i.e. ACCEL or PLR\n",
    "        \"easy_start\": True,            # Whether to fill the buffer with easy levels first i.e. minimum number of blocks\n",
    "        \n",
    "        \"parallel_regret\": False       # Whether to use parallel GAE-based regret calculation\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "config[\"edit_levels\"] = False\n",
    "config[\"easy_start\"] = False\n",
    "print(f\"Running PLR with config: {config}\")\n",
    "model_plr = main_accel(**config)\n",
    "\n",
    "print(\"\\n\\n============================================\\n\\n\")\n",
    "\n",
    "config[\"edit_levels\"] = True\n",
    "config[\"easy_start\"] = False\n",
    "print(f\"Running ACCEL with config: {config}\")\n",
    "model_accel = main_accel(**config)\n",
    "\n",
    "print(\"\\n\\n============================================\\n\\n\")\n",
    "\n",
    "\n",
    "config[\"edit_levels\"] = True\n",
    "config[\"easy_start\"] = True\n",
    "print(f\"Running ACCEL with easy start with config: {config}\")\n",
    "model_accel_easy = main_accel(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating level 1 with 11 blocks for model PLR...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating level 2 with 22 blocks for model PLR...\n",
      "Evaluating level 3 with 33 blocks for model PLR...\n",
      "\n",
      "Evaluating level 1 with 11 blocks for model ACCEL...\n",
      "Evaluating level 2 with 22 blocks for model ACCEL...\n",
      "Evaluating level 3 with 33 blocks for model ACCEL...\n",
      "\n",
      "Evaluating level 1 with 11 blocks for model ACCEL-EasyStart...\n",
      "Evaluating level 2 with 22 blocks for model ACCEL-EasyStart...\n",
      "Evaluating level 3 with 33 blocks for model ACCEL-EasyStart...\n",
      "\n",
      "Model: PLR\n",
      "Level 1 - Complexity 11: 0.59\n",
      "Level 2 - Complexity 22: 0.53\n",
      "Level 3 - Complexity 33: 0.24\n",
      "\n",
      "Model: ACCEL\n",
      "Level 1 - Complexity 11: 0.64\n",
      "Level 2 - Complexity 22: 0.50\n",
      "Level 3 - Complexity 33: 0.33\n",
      "\n",
      "Model: ACCEL-EasyStart\n",
      "Level 1 - Complexity 11: 0.64\n",
      "Level 2 - Complexity 22: 0.46\n",
      "Level 3 - Complexity 33: 0.22\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {'PLR': model_plr, 'ACCEL': model_accel, 'ACCEL-EasyStart': model_accel_easy}\n",
    "#models = {'ACCEL-EasyStart': model_accel_easy}\n",
    "difficulties = 3\n",
    "# Generate n levels difficulties with increasing complexity, for each level generate m configs\n",
    "\n",
    "config[\"grid_size\"] = 11\n",
    "\n",
    "levels = []\n",
    "for i in range(difficulties):\n",
    "    level = []\n",
    "    for _ in range(10):\n",
    "        cfg = random_config(config[\"grid_size\"], num_blocks=config[\"grid_size\"]*(i+1))\n",
    "        #print_level_from_config(cfg)\n",
    "        level.append(cfg)\n",
    "    levels.append(level)\n",
    "\n",
    "# Evaluate the model on the generated levels\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    results[model_name] = []\n",
    "    for i, level in enumerate(levels):\n",
    "        print(f\"Evaluating level {i + 1} with {config['grid_size']*(i+1)} blocks for model {model_name}...\")\n",
    "        r = []\n",
    "        for j, cfg in enumerate(level):\n",
    "            # Create vectorized environment\n",
    "            env = create_vectorized_env(cfg, n_envs=8)\n",
    "            mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=20, deterministic=True)\n",
    "            r.append(mean_reward)\n",
    "        results[model_name].append(r)\n",
    "    print()\n",
    "    \n",
    "# Print mean rewards for each level\n",
    "for model_name in models.keys():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for i, level in enumerate(levels):\n",
    "        print(f\"Level {i + 1} - Complexity {config['grid_size']*(i+1)}: {np.mean(results[model_name][i]):.2f}\")\n",
    "    print()\n",
    "\n",
    "# Boxplot of results, a plot for each level complexity comparing models\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, level in enumerate(levels):\n",
    "    plt.subplot(1, difficulties, i + 1)\n",
    "    plt.boxplot([results[model_name][i] for model_name in models.keys()])\n",
    "    plt.xticks([1, 2, 3], [model_name for model_name in models.keys()])\n",
    "    plt.title(f\"Level {i + 1} - Complexity {config['grid_size']*(i+1)}\")\n",
    "    plt.ylabel(\"Mean Reward\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model PLR on previously evaluated levels...\n",
      "Level 1 - Complexity 4:\n",
      "  Config 1: 0.95\n",
      "  Config 2: 0.94\n",
      "  Config 3: 0.95\n",
      "  Config 4: 0.96\n",
      "  Config 5: 0.93\n",
      "  Config 6: 0.96\n",
      "  Config 7: 0.00\n",
      "  Config 8: 0.00\n",
      "  Config 9: 0.97\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLevel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Complexity \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, cfg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(level):\n\u001b[1;32m---> 31\u001b[0m     mean_reward \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Config \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_reward\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[1;32mIn[29], line 12\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(model, config)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (terminated \u001b[38;5;129;01mor\u001b[39;00m truncated):\n\u001b[0;32m     11\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     14\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[2], line 134\u001b[0m, in \u001b[0;36mMyCustomGrid.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    Same for step: override to convert the dict observation into an image only.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_obs(obs)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obs, reward, done, truncated, info\n",
      "File \u001b[1;32mc:\\Users\\Emanuele\\miniconda3\\envs\\accel_env_cuda\\Lib\\site-packages\\minigrid\\minigrid_env.py:591\u001b[0m, in \u001b[0;36mMiniGridEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    588\u001b[0m     truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 591\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    593\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_obs()\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs, reward, terminated, truncated, {}\n",
      "File \u001b[1;32mc:\\Users\\Emanuele\\miniconda3\\envs\\accel_env_cuda\\Lib\\site-packages\\minigrid\\minigrid_env.py:773\u001b[0m, in \u001b[0;36mMiniGridEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    771\u001b[0m font_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m22\u001b[39m\n\u001b[0;32m    772\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmission\n\u001b[1;32m--> 773\u001b[0m font \u001b[38;5;241m=\u001b[39m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfreetype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSysFont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_font\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    774\u001b[0m text_rect \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mget_rect(text, size\u001b[38;5;241m=\u001b[39mfont_size)\n\u001b[0;32m    775\u001b[0m text_rect\u001b[38;5;241m.\u001b[39mcenter \u001b[38;5;241m=\u001b[39m bg\u001b[38;5;241m.\u001b[39mget_rect()\u001b[38;5;241m.\u001b[39mcenter\n",
      "File \u001b[1;32mc:\\Users\\Emanuele\\miniconda3\\envs\\accel_env_cuda\\Lib\\site-packages\\pygame\\freetype.py:78\u001b[0m, in \u001b[0;36mSysFont\u001b[1;34m(name, size, bold, italic, constructor)\u001b[0m\n\u001b[0;32m     75\u001b[0m         font\u001b[38;5;241m.\u001b[39moblique \u001b[38;5;241m=\u001b[39m italic\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m font\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SysFont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitalic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Emanuele\\miniconda3\\envs\\accel_env_cuda\\Lib\\site-packages\\pygame\\sysfont.py:460\u001b[0m, in \u001b[0;36mSysFont\u001b[1;34m(name, size, bold, italic, constructor)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m italic \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gotitalic:\n\u001b[0;32m    458\u001b[0m     set_italic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfontname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_bold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_italic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Emanuele\\miniconda3\\envs\\accel_env_cuda\\Lib\\site-packages\\pygame\\freetype.py:73\u001b[0m, in \u001b[0;36mSysFont.<locals>.constructor\u001b[1;34m(fontpath, size, bold, italic)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconstructor\u001b[39m(fontpath, size, bold, italic):\n\u001b[1;32m---> 73\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[43mFont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfontpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     font\u001b[38;5;241m.\u001b[39mstrong \u001b[38;5;241m=\u001b[39m bold\n\u001b[0;32m     75\u001b[0m     font\u001b[38;5;241m.\u001b[39moblique \u001b[38;5;241m=\u001b[39m italic\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_model(model, config):\n",
    "    env = MyCustomGrid(config, render_mode='human')\n",
    "    obs, _ = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    total_reward = 0\n",
    "    i = 0\n",
    "\n",
    "    # Continue until either terminated or truncated is True\n",
    "    while not (terminated or truncated):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        i += 1\n",
    "\n",
    "    return total_reward\n",
    "\n",
    "\n",
    "# Test the models on a few levels\n",
    "#for i in range(30):\n",
    "    #test_model(model_plr, random_config(8))\n",
    "    #test_model(model_accel, random_config(8))\n",
    "    #test_model(model_accel_easy, random_config(8))\n",
    "    \n",
    "# Test the models on previously evaluated levels\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Testing model {model_name} on previously evaluated levels...\")\n",
    "    for i, level in enumerate(levels):\n",
    "        print(f\"Level {i + 1} - Complexity {(i+2)**2}:\")\n",
    "        for j, cfg in enumerate(level):\n",
    "            mean_reward = test_model(model, cfg)\n",
    "            print(f\"  Config {j + 1}: {mean_reward:.2f}\")\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Editor Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random level and visualize it\n",
    "random_cnf = random_config(8)\n",
    "print_level_from_config(random_cnf)\n",
    "print(\"random_cnf:\", random_cnf)\n",
    "\n",
    "# Edit the random level and visualize it\n",
    "edited_config = edit_config(random_cnf)\n",
    "print_level_from_config(edited_config)\n",
    "\n",
    "# Edit the random level and visualize it\n",
    "edited_config = edit_config(random_cnf)\n",
    "print_level_from_config(edited_config)\n",
    "\n",
    "# Edit the random level and visualize it\n",
    "edited_config = edit_config(random_cnf)\n",
    "print_level_from_config(edited_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maze generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_maze(width, height):\n",
    "    maze = [[1 for _ in range(width)] for _ in range(height)]  # 1 for walls\n",
    "    stack = []\n",
    "    directions = [(0, 2), (0, -2), (2, 0), (-2, 0)]\n",
    "\n",
    "    def is_valid(x, y):\n",
    "        return 0 < x < height - 1 and 0 < y < width - 1 and maze[x][y] == 1\n",
    "\n",
    "    def carve(x, y):\n",
    "        maze[x][y] = 0\n",
    "        random.shuffle(directions)\n",
    "        for dx, dy in directions:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            if is_valid(nx, ny):\n",
    "                maze[x + dx // 2][y + dy // 2] = 0\n",
    "                carve(nx, ny)\n",
    "\n",
    "    carve(1, 1)  # Start at (1, 1)\n",
    "\n",
    "    return maze\n",
    "\n",
    "# Display the maze\n",
    "def print_maze(maze):\n",
    "    for row in maze:\n",
    "        print(\"\".join(\"█\" if cell == 1 else \" \" for cell in row))\n",
    "\n",
    "maze = generate_maze(21, 21)\n",
    "print_maze(maze)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomMaze(MiniGridEnv):\n",
    "    \"\"\"\n",
    "    Simple MiniGrid environment that places random wall tiles\n",
    "    according to a config dict, returning only the 'image' observation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config=None, **kwargs):\n",
    "        if config is None:\n",
    "            config = {}\n",
    "        self.config = config\n",
    "\n",
    "        # Extract parameters from config\n",
    "        self.width = config.get(\"width\")\n",
    "        self.height = config.get(\"height\")\n",
    "        self.num_blocks = config.get(\"num_blocks\")\n",
    "        self.custom_seed = config.get(\"seed_val\")\n",
    "        \n",
    "        \n",
    "        # Create a random number generator with the custom seed\n",
    "        self.rng = np.random.default_rng(seed=self.custom_seed)\n",
    "\n",
    "        grid_size = max(self.width, self.height)\n",
    "\n",
    "        mission_space = MissionSpace(mission_func=lambda: \"get to the green goal square\")\n",
    "\n",
    "        super().__init__(\n",
    "            grid_size=grid_size,\n",
    "            max_steps=self.width * self.height * 2, # max_steps is typically 2x the grid size\n",
    "            see_through_walls=False,\n",
    "            agent_view_size=5,                      # Size of the agent's view square\n",
    "            mission_space=mission_space,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # Manually define our observation_space as a single Box (the image).\n",
    "        # By default, MiniGrid's image shape is (view_size, view_size, 3) if using partial obs,\n",
    "        # or (height, width, 3) if using full-grid observation. We'll do full-grid here:\n",
    "        # We'll define (self.height, self.width, 3) as the shape.\n",
    "        # In practice, \"image\" shape can vary if partial observations are used.\n",
    "        self.observation_space = Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(self.agent_view_size, self.agent_view_size, 3),\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "\n",
    "    \n",
    "    def _gen_grid(self, width, height):\n",
    "        \"\"\"\n",
    "        Generate the grid layout for a new episode using the DFS Maze Generation Algorithm.\n",
    "        \"\"\"\n",
    "        # Create an empty grid of the \"true\" width x height from config\n",
    "        self.grid = Grid(self.width, self.height)\n",
    "        # Surround the grid with walls\n",
    "        self.grid.wall_rect(0, 0, self.width, self.height)\n",
    "\n",
    "        # Initialize the maze as walls\n",
    "        maze = [[1 for _ in range(self.width)] for _ in range(self.height)]\n",
    "\n",
    "        # Define directions for DFS\n",
    "        directions = [(0, 2), (0, -2), (2, 0), (-2, 0)]\n",
    "\n",
    "        def is_valid(x, y):\n",
    "            \"\"\"Check if a cell is valid for carving.\"\"\"\n",
    "            return 0 < x < self.height - 1 and 0 < y < self.width - 1 and maze[x][y] == 1\n",
    "\n",
    "        def carve(x, y):\n",
    "            \"\"\"Carve passages in the maze using DFS.\"\"\"\n",
    "            maze[x][y] = 0  # Mark the cell as part of the maze\n",
    "            self.grid.set(x, y, None)  # Clear the wall in the grid\n",
    "            self.rng.shuffle(directions)\n",
    "            for dx, dy in directions:\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if is_valid(nx, ny):\n",
    "                    # Remove the wall between cells\n",
    "                    maze[x + dx // 2][y + dy // 2] = 0\n",
    "                    self.grid.set(x + dx // 2, y + dy // 2, None)\n",
    "                    carve(nx, ny)\n",
    "\n",
    "        # Start carving from the top-left corner\n",
    "        carve(1, 1)\n",
    "\n",
    "        # Place the goal object in a random position not occupied by a wall\n",
    "        while True:\n",
    "            r = self.rng.integers(1, self.height - 1)\n",
    "            c = self.rng.integers(1, self.width - 1)\n",
    "            if self.grid.get(c, r) is None:\n",
    "                self.put_obj(Goal(), c, r)\n",
    "                break\n",
    "\n",
    "        # Place the agent in a random position not occupied by a wall and not on the goal\n",
    "        while True:\n",
    "            r = self.rng.integers(1, self.height - 1)\n",
    "            c = self.rng.integers(1, self.width - 1)\n",
    "            if self.grid.get(c, r) is None:\n",
    "                self.place_agent(top=(c, r), rand_dir=True)\n",
    "                break\n",
    "    \n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Override reset to ensure we only return the 'image' array\n",
    "        instead of a dict with 'image' and 'mission'.\n",
    "        \"\"\"\n",
    "        obs, info = super().reset(**kwargs)\n",
    "        obs = self._convert_obs(obs)\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Same for step: override to convert the dict observation into an image only.\n",
    "        \"\"\"\n",
    "        obs, reward, done, truncated, info = super().step(action)\n",
    "        obs = self._convert_obs(obs)\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "    def _convert_obs(self, original_obs):\n",
    "        \"\"\"\n",
    "        original_obs is typically {'image':..., 'mission':...}.\n",
    "        We'll just return original_obs['image'] to get a Box(low=0,high=255) shape.\n",
    "        \"\"\"\n",
    "        return original_obs[\"image\"]\n",
    "        #return np.transpose(original_obs[\"image\"], (2, 0, 1))\n",
    "\n",
    "\n",
    "\n",
    "def print_maze_from_config(config):\n",
    "    env = MyCustomMaze(config, render_mode='rgb_array')\n",
    "    env.reset()\n",
    "    full_level_image = env.render()  # This should return an RGB image of the full grid\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(full_level_image)\n",
    "    plt.title(\"Maze Configuration: \" + str(config))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Generate a random maze and visualize it\n",
    "random_maze = random_config(6)\n",
    "print_maze_from_config(random_maze)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE, NOT VECORIZED, REDUNDANT CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ====================================================\n",
    "# 4. Main ACCEL Loop\n",
    "# ====================================================\n",
    "\n",
    "def main_accel_demo(total_iterations, replay_prob, train_steps, level_buffer_size,\n",
    "                    initial_fill_size, grid_size):\n",
    "    \n",
    "    \n",
    "    # Create a level buffer to store generated levels and their scores\n",
    "    level_buffer = LevelBuffer(max_size=level_buffer_size)\n",
    "    iteration_regrets = []\n",
    "        \n",
    "    #Create a dummy environment to initialize the model\n",
    "    dummy_env = MyCustomGrid(random_config(grid_size))\n",
    "    vectorized_env = create_vectorized_env(dummy_env, n_envs=4)\n",
    "\n",
    "    # Initialize student model with PPO\n",
    "    print(\"Initializing student model PPO...\")\n",
    "    student_model = initialize_ppo(dummy_env)\n",
    "\n",
    "    skipped = 0\n",
    "\n",
    "    # Populate buffer with initial levels\n",
    "    print(f\"Populating buffer with {initial_fill_size} initial levels with regret != 0...\")\n",
    "    for _ in range(initial_fill_size + skipped):\n",
    "        cfg = random_config(grid_size)\n",
    "        regret = calculate_regret_gae(MyCustomGrid(cfg), student_model, max_steps=1000, gamma=0.99, lam=0.95)\n",
    "        \n",
    "        # Skip levels with 0 regret\n",
    "        if regret == 0:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        level_buffer.add(cfg, regret)\n",
    "        \n",
    "    \n",
    "    print(\"\\nDone. Number of skipped levels with zero regret:\", skipped)\n",
    "    \n",
    "    skipped = 0\n",
    "    iteration = 0\n",
    "    # Main ACCEL loop\n",
    "    print(\"\\nMain ACCEL loop...\")\n",
    "    while iteration < total_iterations + skipped:\n",
    "        print(f\"\\n=== ITERATION {iteration + 1}/{total_iterations} SKIPPED {skipped} ===\")\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Decide whether to use replay or generate a new level\n",
    "        use_replay = np.random.rand() < replay_prob\n",
    "        \n",
    "        # Generates new random levels if you don't use replay\n",
    "        if not use_replay or len(level_buffer.data) == 0:\n",
    "            cfg = random_config(grid_size)\n",
    "            regret = calculate_regret_gae(MyCustomGrid(cfg), student_model, max_steps=100, gamma=0.99, lam=0.95)\n",
    "            \n",
    "            if regret == 0:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            \n",
    "            level_buffer.add(cfg, regret)\n",
    "            print(f\"  Sampled new config, regret={regret:.3f}\")\n",
    "        else:\n",
    "            # Replays an existing layer, edits it, and evaluates the new layer\n",
    "            old_cfg = level_buffer.sample_config()\n",
    "            env = MyCustomGrid(old_cfg)\n",
    "            \n",
    "            student_model.set_env(env)\n",
    "            student_model.learn(total_timesteps=train_steps)\n",
    "\n",
    "            new_cfg = edit_config(old_cfg)\n",
    "            regret = calculate_regret_gae(MyCustomGrid(new_cfg), student_model, max_steps=100, gamma=0.99, lam=0.95)\n",
    "            \n",
    "            if regret == 0:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            \n",
    "            level_buffer.add(new_cfg, regret)\n",
    "            print(f\"  Replayed + mutated config, regret={regret:.3f}\")\n",
    "        \n",
    "        iteration_regrets.append(regret)\n",
    "    \n",
    "    print(\"\\nDone. Number of skipped levels with zero regret:\", skipped)\n",
    "\n",
    "    # Visualize progress of the regret over iterations.\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(iteration_regrets, marker='o')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Regret\")\n",
    "    plt.title(\"Regret Progress during ACCEL Training\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    config = {\n",
    "        \"grid_size\": 8,\n",
    "        \n",
    "        \"total_iterations\": 64,\n",
    "        \"train_steps\": 1024,\n",
    "\n",
    "        \"replay_prob\": 0.7,           # Probability of replaying a level and editing it vs. generating a new one\n",
    "        \"level_buffer_size\": 128,     # Maximum number of levels to store in the buffer\n",
    "        \"initial_fill_size\": 64,      # Number of levels to pre-fill the buffer with\n",
    "        \"regret_threshold\": 0.0,      # Minimum regret threshold to consider a level for the buffer\n",
    "        \n",
    "        \"n_envs\": 8,                  # Number of parallel environments to use for training\n",
    "        \n",
    "        \"edit_levels\": True,          # Whether to edit levels during training i.e. ACCEL or PLR\n",
    "        \"easy_start\": True            # Whether to fill the buffer with easy levels first i.e. minimum number of blocks\n",
    "    }\n",
    "    \n",
    "    print(\"Running ACCEL with config:\")\n",
    "    print(config, \"\\n\")\n",
    "    \n",
    "    main_accel(**config)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accel_env_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
